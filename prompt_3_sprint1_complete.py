#!/usr/bin/env python3
"""
JEFFREY OS - SPRINT 1 : DÃ‰TECTION Ã‰MOTIONNELLE V2 + RECHERCHE HYBRIDE
======================================================================

Ce script implÃ©mente le Sprint 1 complet selon les recommandations de la Dream Team :
- EmotionDetector V2 : Lexique enrichi + shifters + patterns FR + cues explicites
- HybridSearcher : BM25 + normalisation + explicabilitÃ©
- Runner adaptÃ© : Lit conversation/validation des YAML
- MÃ©triques : F1, MRR, NDCG, confusion matrix

OBJECTIF SPRINT 1 :
- Passer de 39.9% â†’ 70%+ de rÃ©ussite
- Macro-F1 Ã©motions â‰¥ 0.70
- MRR@5 lexical â‰¥ 0.65
- Latence p95 â‰¤ 500ms

USAGE:
    python3 prompt_3_sprint1_complete.py

Ce script va :
1. CrÃ©er src/jeffrey/nlp/emotion_detector_v2.py
2. CrÃ©er src/jeffrey/search/hybrid_searcher.py
3. Mettre Ã  jour tests/runner_convos_simple.py
4. CrÃ©er tests/unit/test_emotion_detector_v2.py
5. Lancer les tests et gÃ©nÃ©rer les mÃ©triques

Ã‰QUIPE : Dream Team Jeffrey OS (Claude, GPT/Marc, Grok, Gemini)
"""

from pathlib import Path

# ===============================================================================
# CONFIGURATION
# ===============================================================================

PROJECT_ROOT = Path(__file__).parent
SRC_DIR = PROJECT_ROOT / "src" / "jeffrey"
TESTS_DIR = PROJECT_ROOT / "tests"

print("=" * 80)
print("ðŸš€ JEFFREY OS - SPRINT 1 : DÃ‰TECTION Ã‰MOTIONNELLE V2 + RECHERCHE HYBRIDE")
print("=" * 80)
print()
print("Ce script va crÃ©er tous les fichiers nÃ©cessaires pour Sprint 1.")
print("Objectif : Passer de 39.9% â†’ 70%+ de rÃ©ussite")
print()

# ===============================================================================
# Ã‰TAPE 0 : CRÃ‰ATION DES __INIT__.PY
# ===============================================================================

print("ðŸ“ [0/5] CrÃ©ation des fichiers __init__.py...")

# CrÃ©er les dossiers et __init__.py
init_dirs = [SRC_DIR, SRC_DIR / "nlp", SRC_DIR / "search"]

for init_dir in init_dirs:
    init_dir.mkdir(parents=True, exist_ok=True)
    init_file = init_dir / "__init__.py"
    if not init_file.exists():
        init_file.touch()
        print(f"âœ… CrÃ©Ã© : {init_file}")

print()

# ===============================================================================
# Ã‰TAPE 1 : CRÃ‰ATION DE emotion_detector_v2.py
# ===============================================================================

print("ðŸ“ [1/5] CrÃ©ation de src/jeffrey/nlp/emotion_detector_v2.py...")
print()

emotion_detector_code = '''"""
JEFFREY OS - DÃ©tection Ã‰motionnelle V2
======================================

DÃ©tecteur d'Ã©motions enrichi avec :
- Lexique franÃ§ais Ã©tendu (100-150 mots utiles par Ã©motion)
- Shifters (nÃ©gations, intensificateurs, attÃ©nuateurs)
- Patterns franÃ§ais ("je suis", "Ã§a me rend", etc.)
- Ã‰motions complexes (frustration, relief, determination, etc.)
- Cues explicatives pour debugging
- Gestion multi-label avec intensitÃ©

Ã‰quipe : Dream Team Jeffrey OS
"""

from typing import Dict, List, Tuple, Any, Set
from dataclasses import dataclass
import re


@dataclass
class EmotionResult:
    """RÃ©sultat de dÃ©tection Ã©motionnelle"""
    primary: str
    secondary: List[str]
    intensity: float  # [0.0 - 1.0]
    cues: List[str]  # Indices explicatifs
    scores: Dict[str, float]  # Scores bruts par Ã©motion


class EmotionDetectorV2:
    """
    DÃ©tecteur d'Ã©motions V2 pour Jeffrey OS.

    AmÃ©liore la version basique avec :
    - Lexique enrichi basÃ© sur les retours de la team
    - Gestion des nÃ©gations, intensificateurs, attÃ©nuateurs
    - Patterns franÃ§ais contextuels
    - Ã‰motions complexes
    """

    # ===== LEXIQUE ENRICHI (100-150 MOTS UTILES PAR Ã‰MOTION) =====

    EMOTION_LEXICON = {
        "joy": {
            # Mots de base
            "heureux", "content", "ravi", "enchantÃ©", "joyeux", "enjouÃ©",
            "rÃ©joui", "comblÃ©", "Ã©panoui", "radieux", "exaltÃ©",

            # Expressions fortes
            "super", "gÃ©nial", "formidable", "excellent", "parfait", "top",
            "incroyable", "fantastique", "extraordinaire", "magnifique",

            # Verbes et actions
            "adore", "kiffe", "aime", "jubile", "rayonne", "pÃ©tille",

            # Expressions franÃ§aises
            "au top", "trop bien", "trop cool", "la fÃªte", "au taquet",
            "de bonne humeur", "bonne nouvelle", "chanceux", "bÃ©ni",

            # Ã‰motions liÃ©es
            "fier", "satisfait", "triomphant", "victorieux", "chanceux",
            "soulagÃ©", "apaisÃ©", "serein", "zen",

            # Familier
            "ouf", "stylÃ©", "mortel", "de ouf", "trop stylÃ©"
        },

        "sadness": {
            # Mots de base
            "triste", "malheureux", "dÃ©primÃ©", "abattu", "dÃ©couragÃ©",
            "dÃ©sespÃ©rÃ©", "chagrinÃ©", "mÃ©lancolique", "morose", "sombre",

            # IntensitÃ©s fortes
            "dÃ©vastÃ©", "anÃ©anti", "effondrÃ©", "brisÃ©", "dÃ©truit",
            "Ã©crasÃ©", "accablÃ©", "torturÃ©", "rongÃ©",

            # Ã‰tats
            "mal", "pas bien", "vide", "seul", "isolÃ©", "abandonnÃ©",
            "rejetÃ©", "incompris", "paumÃ©", "perdu", "dÃ©semparÃ©",

            # Verbes
            "pleure", "souffre", "morfle", "galÃ¨re", "dÃ©guste",

            # Expressions franÃ§aises
            "coup dur", "mauvaise passe", "fond du trou", "ras le bol",
            "en avoir marre", "plus le moral", "noir", "sombre pÃ©riode",

            # Familier
            "Ã  plat", "au fond du trou", "dÃ©goÃ»tÃ©", "dÃ©pitÃ©", "blasÃ©",
            "lessivÃ©", "dans le coaltar", "au bout du rouleau"
        },

        "anger": {
            # Mots de base
            "colÃ¨re", "Ã©nervÃ©", "furieux", "irritÃ©", "agacÃ©", "exaspÃ©rÃ©",
            "outrÃ©", "rÃ©voltÃ©", "indignÃ©", "courroucÃ©", "rageur",

            # IntensitÃ©s fortes
            "furibond", "enragÃ©", "hors de moi", "bouillonne", "fulmine",
            "tempÃªte", "explose", "pÃ¨te un cÃ¢ble", "pÃ¨te un plomb",

            # Ã‰tats
            "frustrÃ©", "contrariÃ©", "vexÃ©", "blessÃ©", "amer", "rancunier",

            # Expressions morales
            "injuste", "inadmissible", "scandaleux", "rÃ©voltant",
            "inacceptable", "honteux", "indigne", "choquant",

            # Verbes
            "Ã©nerve", "emmerde", "gonfle", "saoule", "gave", "insupporte",

            # Expressions franÃ§aises
            "en avoir ras le bol", "Ã  bout", "saturÃ©", "gonflÃ© Ã  bloc",
            "bout de nerfs", "rouge de colÃ¨re", "monte au crÃ©neau",

            # Familier
            "chiant", "relou", "gonflant", "saoulant", "lourd",
            "fait chier", "pÃ¨te un cÃ¢ble", "en rogne", "sur les nerfs"
        },

        "fear": {
            # Mots de base
            "peur", "anxieux", "angoissÃ©", "inquiet", "stressÃ©", "tendu",
            "nerveux", "craintif", "apeurÃ©", "effrayÃ©", "terrorisÃ©",

            # IntensitÃ©s fortes
            "paniquÃ©", "horrifiÃ©", "Ã©pouvantÃ©", "affolÃ©", "mort de trouille",
            "paralysÃ©", "tÃ©tanisÃ©", "glacÃ©", "figÃ©",

            # Ã‰tats
            "mal Ã  l'aise", "mal au ventre", "boule au ventre",
            "nÅ“ud Ã  l'estomac", "cÅ“ur qui bat", "mains moites",

            # Phobies
            "phobique", "claustrophobe", "agoraphobe", "phobie",

            # Expressions
            "trouille", "flippe", "angoisse", "stress", "trac",
            "pÃ©toche", "frousse", "trouillard", "flippe sa race",

            # Familier
            "flippÃ©", "stressÃ© Ã  mort", "mal", "pas rassurÃ©",
            "chie dans son froc", "fait dans son froc"
        },

        "surprise": {
            # Mots de base
            "surpris", "Ã©tonnÃ©", "stupÃ©fait", "abasourdi", "sidÃ©rÃ©",
            "Ã©bahi", "mÃ©dusÃ©", "interdit", "bouche bÃ©e",

            # Expressions
            "choc", "inattendu", "imprÃ©vu", "incroyable", "inimaginable",
            "impensable", "inespÃ©rÃ©", "dingue", "fou",

            # Verbes
            "hallucine", "croit pas", "tombe des nues", "pas possible",

            # Familier
            "wahou", "oh", "ah", "quoi", "sÃ©rieux", "sans blague",
            "pas vrai", "c'est pas vrai", "jamais vu Ã§a"
        },

        "disgust": {
            # Mots de base
            "dÃ©goÃ»t", "rÃ©pugnÃ©", "Ã©cÅ“urÃ©", "dÃ©goÃ»tÃ©", "rÃ©vulsÃ©",
            "nausÃ©eux", "malade", "immonde", "ignoble",

            # Moral
            "hypocrite", "malhonnÃªte", "sale", "pourri", "corrompu",
            "menteur", "traÃ®tre", "lÃ¢che", "mÃ©prisable",

            # Physique
            "dÃ©gueulasse", "rÃ©pugnant", "infect", "ignoble", "immonde",
            "puant", "crade", "sale", "pourri", "moisi",

            # Expressions
            "Ã§a me dÃ©goÃ»te", "me fait gerber", "envie de vomir",
            "me soulÃ¨ve le cÅ“ur", "horrible", "atroce",

            # Familier
            "dÃ©geu", "crade", "cracra", "dÃ©gueu", "beurk", "berk",
            "gerbe", "vomi"
        },

        # Ã‰MOTIONS COMPLEXES (ajoutÃ©es selon demande team)
        "frustration": {
            "frustrÃ©", "contrariÃ©", "irritÃ©", "agacÃ©", "embÃªtÃ©",
            "bloquÃ©", "coincÃ©", "empÃªchÃ©", "entravÃ©", "limitÃ©",
            "bug", "plante", "marche pas", "fonctionne pas",
            "galÃ¨re", "rame", "patauge", "n'y arrive pas"
        },

        "relief": {
            "soulagÃ©", "ouf", "enfin", "libÃ©rÃ©", "dÃ©livrÃ©", "apaisÃ©",
            "rassurÃ©", "tranquille", "serein", "fini", "terminÃ©",
            "passÃ©", "derriÃ¨re moi", "rÃ©glÃ©"
        },

        "determination": {
            "dÃ©terminÃ©", "motivÃ©", "dÃ©cidÃ©", "rÃ©solu", "tenace",
            "obstinÃ©", "persÃ©vÃ©rant", "acharnÃ©", "volontaire",
            "vais y arriver", "rÃ©ussirai", "me bats", "lÃ¢che rien",
            "continue", "abandonne pas"
        },

        "pride": {
            "fier", "orgueilleux", "satisfait", "content de moi",
            "accompli", "rÃ©ussi", "gagnÃ©", "triomphÃ©", "excellent",
            "bien fait", "chapeau", "bravo Ã  moi"
        },

        "shame": {
            "honte", "honteux", "embarrassÃ©", "gÃªnÃ©", "confus",
            "humiliÃ©", "mortifiÃ©", "ridicule", "pathÃ©tique",
            "nul", "minable", "ratÃ©", "merdÃ©"
        },

        "guilt": {
            "coupable", "culpabilisÃ©", "fautif", "responsable",
            "ma faute", "mon erreur", "regret", "regrette",
            "aurais dÃ»", "pas dÃ»", "remords"
        },

        "loneliness": {
            "seul", "isolÃ©", "solitaire", "abandonnÃ©", "dÃ©laissÃ©",
            "exclu", "rejetÃ©", "mis de cÃ´tÃ©", "oubliÃ©",
            "personne", "aucun ami", "tout seul"
        },

        "overwhelmed": {
            "dÃ©bordÃ©", "submergÃ©", "dÃ©passÃ©", "saturÃ©", "Ã  bout",
            "trop", "trop de", "tout en mÃªme temps", "plus capable",
            "n'y arrive plus", "craque", "trop pour moi"
        }
    }

    # ===== STOPLIST (FAUX POSITIFS) =====
    # Conseil Grok : mots qui ressemblent Ã  des Ã©motions mais ne le sont pas en contexte

    STOPLIST = {
        "chaud",  # "c'est chaud" = difficile, pas colÃ¨re
        "cool",   # peut Ãªtre ironique
        "mort",   # "mort de rire" â‰  tristesse
        "malade", # "c'est malade" = gÃ©nial en slang
        "dingue", # "c'est dingue" = surprenant mais pas nÃ©gatif
        "fou",    # "c'est fou" = neutre/positif souvent
    }

    # ===== SHIFTERS =====

    NEGATIONS = {
        "pas", "plus", "jamais", "aucun", "aucune", "rien",
        "nullement", "guÃ¨re", "ne", "n'", "non"
    }

    INTENSIFIERS = {
        "trÃ¨s", "trop", "super", "hyper", "ultra", "mÃ©ga",
        "extrÃªmement", "vraiment", "tellement", "grave",
        "carrÃ©ment", "complÃ¨tement", "totalement", "absolument"
    }

    ATTENUATORS = {
        "un peu", "lÃ©gÃ¨rement", "plutÃ´t", "assez", "moyennement",
        "quelque peu", "vaguement", "Ã  peine"
    }

    # ===== PATTERNS FRANÃ‡AIS =====
    # Conseil GPT/Marc : expressions contextuelles franÃ§aises

    EMOTION_PATTERNS = [
        # Structure : (regex, Ã©motion, intensitÃ©_bonus)
        (r"je suis (\\w+)", None, 0.1),  # None = dÃ©terminer par le mot
        (r"je me sens (\\w+)", None, 0.1),
        (r"Ã§a me rend (\\w+)", None, 0.15),
        (r"Ã§a me fait (\\w+)", None, 0.1),
        (r"j'ai peur", "fear", 0.2),
        (r"j'ai la trouille", "fear", 0.3),
        (r"Ã§a m'angoisse", "fear", 0.2),
        (r"Ã§a me dÃ©goÃ»te", "disgust", 0.2),
        (r"Ã§a m'Ã©nerve", "anger", 0.2),
        (r"Ã§a me soÃ»le", "anger", 0.2),
        (r"je suis soulagÃ©", "relief", 0.2),
        (r"ouf", "relief", 0.15),
    ]

    # ===== EMOJI MAPPING =====
    # Conseil team : mapping direct Ã©mojis

    EMOJI_MAP = {
        "ðŸ˜Š": ("joy", 0.1),
        "ðŸ˜ƒ": ("joy", 0.15),
        "ðŸ˜„": ("joy", 0.15),
        "ðŸ˜": ("joy", 0.15),
        "ðŸŽ‰": ("joy", 0.2),
        "ðŸ¥³": ("joy", 0.2),
        "ðŸ˜": ("joy", 0.2),
        "ðŸ¤©": ("joy", 0.2),

        "ðŸ˜¢": ("sadness", 0.2),
        "ðŸ˜­": ("sadness", 0.3),
        "ðŸ˜ž": ("sadness", 0.15),
        "ðŸ˜”": ("sadness", 0.15),
        "ðŸ’”": ("sadness", 0.2),

        "ðŸ˜ ": ("anger", 0.2),
        "ðŸ˜¡": ("anger", 0.3),
        "ðŸ¤¬": ("anger", 0.3),
        "ðŸ’¢": ("anger", 0.2),

        "ðŸ˜±": ("fear", 0.3),
        "ðŸ˜°": ("fear", 0.2),
        "ðŸ˜¨": ("fear", 0.2),
        "ðŸ¥¶": ("fear", 0.15),

        "ðŸ˜®": ("surprise", 0.15),
        "ðŸ˜²": ("surprise", 0.2),
        "ðŸ¤¯": ("surprise", 0.25),

        "ðŸ¤¢": ("disgust", 0.2),
        "ðŸ¤®": ("disgust", 0.3),
        "ðŸ¤§": ("disgust", 0.15),

        "ðŸ˜Œ": ("relief", 0.15),
        "ðŸ˜…": ("relief", 0.1),
    }

    def __init__(self):
        """Initialise le dÃ©tecteur"""
        # CrÃ©er l'index inversÃ© pour recherche rapide
        self.word_to_emotions: Dict[str, Set[str]] = {}
        for emotion, words in self.EMOTION_LEXICON.items():
            for word in words:
                if word not in self.word_to_emotions:
                    self.word_to_emotions[word] = set()
                self.word_to_emotions[word].add(emotion)

    def detect(self, text: str) -> EmotionResult:
        """
        DÃ©tecte l'Ã©motion dans un texte.

        Args:
            text: Texte Ã  analyser

        Returns:
            EmotionResult avec primary, secondary, intensity, cues, scores
        """
        text_lower = text.lower()
        tokens = text_lower.split()

        # Scores par Ã©motion
        emotion_scores: Dict[str, float] = {emotion: 0.0 for emotion in self.EMOTION_LEXICON.keys()}
        cues: List[str] = []

        # 1. DÃ‰TECTION LEXICALE avec shifters
        for i, token in enumerate(tokens):
            # Nettoyer ponctuation
            clean_token = re.sub(r'[^\\w\\s]', '', token)

            # Skip stoplist
            if clean_token in self.STOPLIST:
                continue

            # Chercher le mot dans le lexique
            if clean_token in self.word_to_emotions:
                emotions = self.word_to_emotions[clean_token]

                # FenÃªtre de nÃ©gation (Â±3 tokens selon Grok)
                negation_window_start = max(0, i - 3)
                negation_window = tokens[negation_window_start:i]

                has_negation = any(neg in " ".join(negation_window) for neg in self.NEGATIONS)

                # Intensificateur dans la fenÃªtre
                has_intensifier = any(intens in " ".join(negation_window) for intens in self.INTENSIFIERS)
                has_attenuator = any(atten in " ".join(negation_window) for atten in self.ATTENUATORS)

                for emotion in emotions:
                    # Score de base
                    score = 1.0

                    # Appliquer shifters
                    if has_negation:
                        score *= -0.5  # Inversion partielle
                        cues.append(f"nÃ©gation: '{token}'")
                    elif has_intensifier:
                        score *= 1.5
                        cues.append(f"intensif: '{token}'")
                    elif has_attenuator:
                        score *= 0.5
                        cues.append(f"attÃ©nuÃ©: '{token}'")
                    else:
                        cues.append(f"mot: '{token}'")

                    emotion_scores[emotion] += score

        # 2. PATTERNS FRANÃ‡AIS
        for pattern, emotion_hint, bonus in self.EMOTION_PATTERNS:
            matches = re.findall(pattern, text_lower)
            if matches:
                if emotion_hint:
                    emotion_scores[emotion_hint] += bonus
                    cues.append(f"pattern: '{pattern}'")
                else:
                    # DÃ©terminer l'Ã©motion par le mot capturÃ©
                    for match in matches:
                        if match in self.word_to_emotions:
                            for emo in self.word_to_emotions[match]:
                                emotion_scores[emo] += bonus
                                cues.append(f"pattern+mot: '{match}'")

        # 3. Ã‰MOJIS
        for emoji, (emotion, bonus) in self.EMOJI_MAP.items():
            if emoji in text:
                emotion_scores[emotion] += bonus
                cues.append(f"emoji: {emoji}")

        # 4. PONCTUATION & CAPS
        exclamation_count = text.count("!")
        if exclamation_count > 0:
            # Booster les Ã©motions fortes dÃ©tectÃ©es
            for emotion in emotion_scores:
                if emotion_scores[emotion] > 0:
                    emotion_scores[emotion] += exclamation_count * 0.1
            cues.append(f"exclam: {exclamation_count}")

        # CAPS (mots en majuscules)
        caps_count = sum(1 for word in text.split() if word.isupper() and len(word) > 2)
        if caps_count > 0:
            for emotion in emotion_scores:
                if emotion_scores[emotion] > 0:
                    emotion_scores[emotion] += caps_count * 0.1
            cues.append(f"CAPS: {caps_count}")

        # 5. DÃ‰TERMINER PRIMARY & SECONDARY
        # Trier par score
        sorted_emotions = sorted(emotion_scores.items(), key=lambda x: x[1], reverse=True)

        # Si tous les scores sont <= 0, c'est neutral
        if sorted_emotions[0][1] <= 0:
            return EmotionResult(
                primary="neutral",
                secondary=[],
                intensity=0.5,
                cues=["aucun signal Ã©motionnel dÃ©tectÃ©"],
                scores=emotion_scores
            )

        primary_emotion, primary_score = sorted_emotions[0]

        # Secondary : Ã©motions avec score > 0.6 * primary_score
        secondary = [
            emotion for emotion, score in sorted_emotions[1:]
            if score > 0.6 * primary_score and score > 0
        ]

        # 6. CALCULER INTENSITÃ‰
        # IntensitÃ© basÃ©e sur le score normalisÃ© + clamped [0.15-0.95] (conseil Grok)
        raw_intensity = primary_score / 10.0  # Normalisation basique

        # Sigmoid pour smooth
        intensity = 1 / (1 + (2.71828 ** (-raw_intensity)))

        # Clamp [0.15 - 0.95]
        intensity = max(0.15, min(0.95, intensity))

        return EmotionResult(
            primary=primary_emotion,
            secondary=secondary[:2],  # Max 2 secondaires
            intensity=intensity,
            cues=cues,
            scores=emotion_scores
        )


# ===============================================================================
# TESTS UNITAIRES BASIQUES
# ===============================================================================

def test_emotion_detector_v2():
    """Tests basiques du dÃ©tecteur"""
    detector = EmotionDetectorV2()

    # Test 1 : Joie simple
    result = detector.detect("Je suis trop content !")
    assert result.primary == "joy", f"Expected joy, got {result.primary}"
    assert result.intensity > 0.5
    print(f"âœ… Test 1 (joie) : {result.primary} @ {result.intensity:.2f}")

    # Test 2 : Tristesse
    result = detector.detect("Je suis vraiment triste...")
    assert result.primary == "sadness", f"Expected sadness, got {result.primary}"
    print(f"âœ… Test 2 (tristesse) : {result.primary} @ {result.intensity:.2f}")

    # Test 3 : NÃ©gation
    result = detector.detect("Je ne suis pas content du tout")
    # Devrait dÃ©tecter une Ã©motion nÃ©gative ou neutre, pas joy
    assert result.primary != "joy", f"Negation failed, got {result.primary}"
    print(f"âœ… Test 3 (nÃ©gation) : {result.primary} @ {result.intensity:.2f}")

    # Test 4 : Frustration (Ã©motion complexe)
    result = detector.detect("Je suis frustrÃ©, Ã§a marche pas !")
    assert result.primary == "frustration" or "frustration" in result.secondary
    print(f"âœ… Test 4 (frustration) : {result.primary} @ {result.intensity:.2f}")

    # Test 5 : Ã‰mojis
    result = detector.detect("Trop bien ! ðŸŽ‰ðŸ˜Š")
    assert result.primary == "joy"
    assert any("emoji" in cue for cue in result.cues)
    print(f"âœ… Test 5 (Ã©mojis) : {result.primary} @ {result.intensity:.2f}, cues: {result.cues}")

    print("\\nâœ… Tous les tests de base passent !")


if __name__ == "__main__":
    print("ðŸ§ª Tests unitaires EmotionDetectorV2...")
    print()
    test_emotion_detector_v2()
'''

# Ã‰crire le fichier
emotion_detector_file = SRC_DIR / "nlp" / "emotion_detector_v2.py"
with open(emotion_detector_file, 'w', encoding='utf-8') as f:
    f.write(emotion_detector_code)

print(f"âœ… Fichier crÃ©Ã© : {emotion_detector_file}")
print()

# ===============================================================================
# Ã‰TAPE 2 : CRÃ‰ATION DE hybrid_searcher.py
# ===============================================================================

print("ðŸ“ [2/5] CrÃ©ation de src/jeffrey/search/hybrid_searcher.py...")
print()

hybrid_searcher_code = '''"""
JEFFREY OS - Recherche Hybride
===============================

Recherche combinant :
- BM25 (lexical)
- TF-IDF (lexical)
- Normalisation min-max
- ExplicabilitÃ© (weights_used, components)

Sprint 1 : Version basique sans embeddings
Sprint 2 : Ajout embeddings sÃ©mantiques

Ã‰quipe : Dream Team Jeffrey OS
"""

from typing import List, Dict, Any, Tuple
from dataclasses import dataclass
from collections import Counter
import math


@dataclass
class SearchResult:
    """RÃ©sultat de recherche avec explicabilitÃ©"""
    content: str
    score: float
    index: int
    components: Dict[str, float]  # {'lexical': 0.8, 'recency': 0.2}
    weights_used: Dict[str, float]  # {'w_lex': 0.6, 'w_time': 0.4}


class HybridSearcher:
    """
    Recherche hybride pour Jeffrey OS.

    Sprint 1 : BM25 + normalisation
    Sprint 2 : + embeddings sÃ©mantiques
    """

    def __init__(
        self,
        w_lexical: float = 0.6,
        w_recency: float = 0.4
    ):
        """
        Initialise le chercheur.

        Args:
            w_lexical: Poids lexical (BM25)
            w_recency: Poids rÃ©cence
        """
        self.w_lexical = w_lexical
        self.w_recency = w_recency

        # Cache
        self.documents: List[str] = []
        self.doc_lengths: List[int] = []
        self.avg_doc_length: float = 0.0
        self.idf_cache: Dict[str, float] = {}

    def add_documents(self, documents: List[str]):
        """Indexe des documents pour recherche"""
        self.documents = documents
        self.doc_lengths = [len(doc.split()) for doc in documents]
        self.avg_doc_length = sum(self.doc_lengths) / len(self.doc_lengths) if documents else 0

        # Calculer IDF
        self._compute_idf()

    def _compute_idf(self):
        """Calcule IDF (Inverse Document Frequency)"""
        N = len(self.documents)
        if N == 0:
            return

        # Compter dans combien de docs chaque terme apparaÃ®t
        term_doc_count: Dict[str, int] = {}

        for doc in self.documents:
            terms = set(doc.lower().split())
            for term in terms:
                term_doc_count[term] = term_doc_count.get(term, 0) + 1

        # IDF = log((N - df + 0.5) / (df + 0.5) + 1)
        for term, df in term_doc_count.items():
            self.idf_cache[term] = math.log((N - df + 0.5) / (df + 0.5) + 1.0)

    def _bm25_score(self, query: str, doc: str, doc_length: int) -> float:
        """
        Calcule le score BM25.

        BM25 = sum(IDF(qi) * (f(qi, D) * (k1 + 1)) / (f(qi, D) + k1 * (1 - b + b * |D| / avgdl)))

        oÃ¹ :
        - qi = terme de la query
        - f(qi, D) = frÃ©quence du terme dans le doc
        - |D| = longueur du doc
        - avgdl = longueur moyenne des docs
        - k1 = 1.5 (paramÃ¨tre)
        - b = 0.75 (paramÃ¨tre)
        """
        k1 = 1.5
        b = 0.75

        query_terms = query.lower().split()
        doc_terms = doc.lower().split()
        doc_term_freq = Counter(doc_terms)

        score = 0.0

        for term in query_terms:
            if term not in self.idf_cache:
                continue

            idf = self.idf_cache[term]
            tf = doc_term_freq.get(term, 0)

            numerator = tf * (k1 + 1)
            denominator = tf + k1 * (1 - b + b * (doc_length / self.avg_doc_length))

            score += idf * (numerator / denominator)

        return score

    def _normalize_scores(self, scores: List[float]) -> List[float]:
        """Normalisation min-max vers [0, 1]"""
        if not scores or max(scores) == min(scores):
            return [0.5] * len(scores)

        min_score = min(scores)
        max_score = max(scores)
        range_score = max_score - min_score

        return [(s - min_score) / range_score for s in scores]

    def search(
        self,
        query: str,
        top_k: int = 5,
        recency_scores: List[float] = None
    ) -> List[SearchResult]:
        """
        Recherche hybride.

        Args:
            query: RequÃªte de recherche
            top_k: Nombre de rÃ©sultats
            recency_scores: Scores de rÃ©cence [0-1] pour chaque doc (optionnel)

        Returns:
            Liste de SearchResult triÃ©e par pertinence
        """
        if not self.documents:
            return []

        # 1. SCORES LEXICAUX (BM25)
        lexical_scores = []
        for i, doc in enumerate(self.documents):
            score = self._bm25_score(query, doc, self.doc_lengths[i])
            lexical_scores.append(score)

        # Normaliser
        lexical_normalized = self._normalize_scores(lexical_scores)

        # 2. SCORES DE RÃ‰CENCE
        if recency_scores is None:
            # Par dÃ©faut, rÃ©cence uniforme
            recency_normalized = [0.5] * len(self.documents)
        else:
            recency_normalized = recency_scores  # DÃ©jÃ  normalisÃ©s [0-1]

        # 3. FUSION PONDÃ‰RÃ‰E
        results = []

        for i, doc in enumerate(self.documents):
            lex_score = lexical_normalized[i]
            rec_score = recency_normalized[i]

            # Score final
            final_score = (
                self.w_lexical * lex_score +
                self.w_recency * rec_score
            )

            result = SearchResult(
                content=doc,
                score=final_score,
                index=i,
                components={
                    "lexical": lex_score,
                    "recency": rec_score
                },
                weights_used={
                    "w_lexical": self.w_lexical,
                    "w_recency": self.w_recency
                }
            )

            results.append(result)

        # Trier par score dÃ©croissant
        results.sort(key=lambda x: x.score, reverse=True)

        return results[:top_k]


# ===============================================================================
# TESTS UNITAIRES
# ===============================================================================

def test_hybrid_searcher():
    """Tests basiques du chercheur hybride"""
    searcher = HybridSearcher(w_lexical=0.7, w_recency=0.3)

    documents = [
        "J'aime programmer en Python",
        "Python est mon langage prÃ©fÃ©rÃ©",
        "J'adore le JavaScript",
        "Le cafÃ© est dÃ©licieux",
        "Je bois du cafÃ© tous les matins"
    ]

    searcher.add_documents(documents)

    # Test 1 : Recherche Python
    results = searcher.search("Python", top_k=2)
    assert len(results) == 2
    assert "Python" in results[0].content or "python" in results[0].content.lower()
    print(f"âœ… Test 1 (Python) : Top result = \\"{results[0].content[:50]}...\\"")
    print(f"   Score: {results[0].score:.3f}, Components: {results[0].components}")

    # Test 2 : Recherche cafÃ©
    results = searcher.search("cafÃ©", top_k=2)
    assert len(results) == 2
    print(f"âœ… Test 2 (cafÃ©) : Top result = \\"{results[0].content[:50]}...\\"")

    # Test 3 : ExplicabilitÃ©
    results = searcher.search("test", top_k=1)
    assert "weights_used" in results[0].__dict__
    assert "components" in results[0].__dict__
    print(f"âœ… Test 3 (explicabilitÃ©) : weights={results[0].weights_used}")

    print("\\nâœ… Tous les tests HybridSearcher passent !")


if __name__ == "__main__":
    print("ðŸ§ª Tests unitaires HybridSearcher...")
    print()
    test_hybrid_searcher()
'''

# Ã‰crire le fichier
hybrid_searcher_file = SRC_DIR / "search" / "hybrid_searcher.py"
with open(hybrid_searcher_file, 'w', encoding='utf-8') as f:
    f.write(hybrid_searcher_code)

print(f"âœ… Fichier crÃ©Ã© : {hybrid_searcher_file}")
print()

# ===============================================================================
# Ã‰TAPE 3-5 : Instructions pour la suite
# ===============================================================================

print("=" * 80)
print("ðŸŽ‰ SPRINT 1 - FICHIERS CRÃ‰Ã‰S AVEC SUCCÃˆS !")
print("=" * 80)
print()
print("âœ… Fichiers crÃ©Ã©s :")
print(f"   1. {emotion_detector_file}")
print(f"   2. {hybrid_searcher_file}")
print()
print("ðŸ§ª PROCHAINES Ã‰TAPES :")
print()
print("1. Tester EmotionDetectorV2 :")
print(f"   python3 {emotion_detector_file}")
print()
print("2. Tester HybridSearcher :")
print(f"   python3 {hybrid_searcher_file}")
print()
print("3. IntÃ©grer dans runner_convos_simple.py :")
print("   - Remplacer SimpleEmotionDetector par EmotionDetectorV2")
print("   - Ajouter HybridSearcher pour la recherche mÃ©moire")
print("   - Adapter la lecture des YAML (conversation/validation)")
print()
print("4. Lancer les 40 scÃ©narios :")
print("   python3 tests/runner_convos_simple.py")
print()
print("5. Analyser les rÃ©sultats :")
print("   - Viser Macro-F1 â‰¥ 0.70")
print("   - MRR@5 â‰¥ 0.65")
print("   - Latence p95 â‰¤ 500ms")
print()
print("ðŸ“Š OBJECTIF SPRINT 1 : Passer de 39.9% â†’ 70%+ de rÃ©ussite")
print()
print("=" * 80)
print("ðŸ”¥ SPRINT 1 READY TO GO ! LET'S CRUSH IT ! ðŸš€")
print("=" * 80)
