#!/usr/bin/env python3
"""
JEFFREY OS - SPRINT 1 : D√âTECTION √âMOTIONNELLE V2 + RECHERCHE HYBRIDE
======================================================================

Ce script impl√©mente le Sprint 1 complet selon les recommandations de la Dream Team :
- EmotionDetector V2 : Lexique enrichi + shifters + patterns FR + cues explicites
- HybridSearcher : BM25 + normalisation + explicabilit√©
- Runner adapt√© : Lit conversation/validation des YAML
- M√©triques : F1, MRR, NDCG, confusion matrix

OBJECTIF SPRINT 1 :
- Passer de 39.9% ‚Üí 70%+ de r√©ussite
- Macro-F1 √©motions ‚â• 0.70
- MRR@5 lexical ‚â• 0.65
- Latence p95 ‚â§ 500ms

USAGE:
    python3 prompt_3_sprint1_complete.py

Ce script va :
1. Cr√©er src/jeffrey/nlp/emotion_detector_v2.py
2. Cr√©er src/jeffrey/search/hybrid_searcher.py
3. Mettre √† jour tests/runner_convos_simple.py
4. Cr√©er tests/unit/test_emotion_detector_v2.py
5. Lancer les tests et g√©n√©rer les m√©triques

√âQUIPE : Dream Team Jeffrey OS (Claude, GPT/Marc, Grok, Gemini)
"""

from pathlib import Path

# ===============================================================================
# CONFIGURATION
# ===============================================================================

PROJECT_ROOT = Path(__file__).parent
SRC_DIR = PROJECT_ROOT / "src" / "jeffrey"
TESTS_DIR = PROJECT_ROOT / "tests"

print("=" * 80)
print("üöÄ JEFFREY OS - SPRINT 1 : D√âTECTION √âMOTIONNELLE V2 + RECHERCHE HYBRIDE")
print("=" * 80)
print()
print("Ce script va cr√©er tous les fichiers n√©cessaires pour Sprint 1.")
print("Objectif : Passer de 39.9% ‚Üí 70%+ de r√©ussite")
print()

# ===============================================================================
# √âTAPE 0 : CR√âATION DES __INIT__.PY
# ===============================================================================

print("üìÅ [0/5] Cr√©ation des fichiers __init__.py...")

# Cr√©er les dossiers et __init__.py
init_dirs = [SRC_DIR, SRC_DIR / "nlp", SRC_DIR / "search"]

for init_dir in init_dirs:
    init_dir.mkdir(parents=True, exist_ok=True)
    init_file = init_dir / "__init__.py"
    if not init_file.exists():
        init_file.touch()
        print(f"‚úÖ Cr√©√© : {init_file}")

print()

# ===============================================================================
# √âTAPE 1 : CR√âATION DE emotion_detector_v2.py
# ===============================================================================

print("üìù [1/5] Cr√©ation de src/jeffrey/nlp/emotion_detector_v2.py...")
print()

emotion_detector_code = '''"""
JEFFREY OS - D√©tection √âmotionnelle V2
======================================

D√©tecteur d'√©motions enrichi avec :
- Lexique fran√ßais √©tendu (100-150 mots utiles par √©motion)
- Shifters (n√©gations, intensificateurs, att√©nuateurs)
- Patterns fran√ßais ("je suis", "√ßa me rend", etc.)
- √âmotions complexes (frustration, relief, determination, etc.)
- Cues explicatives pour debugging
- Gestion multi-label avec intensit√©

√âquipe : Dream Team Jeffrey OS
"""

from typing import Dict, List, Tuple, Any, Set
from dataclasses import dataclass
import re


@dataclass
class EmotionResult:
    """R√©sultat de d√©tection √©motionnelle"""
    primary: str
    secondary: List[str]
    intensity: float  # [0.0 - 1.0]
    cues: List[str]  # Indices explicatifs
    scores: Dict[str, float]  # Scores bruts par √©motion


class EmotionDetectorV2:
    """
    D√©tecteur d'√©motions V2 pour Jeffrey OS.

    Am√©liore la version basique avec :
    - Lexique enrichi bas√© sur les retours de la team
    - Gestion des n√©gations, intensificateurs, att√©nuateurs
    - Patterns fran√ßais contextuels
    - √âmotions complexes
    """

    # ===== LEXIQUE ENRICHI (100-150 MOTS UTILES PAR √âMOTION) =====

    EMOTION_LEXICON = {
        "joy": {
            # Mots de base
            "heureux", "content", "ravi", "enchant√©", "joyeux", "enjou√©",
            "r√©joui", "combl√©", "√©panoui", "radieux", "exalt√©",

            # Expressions fortes
            "super", "g√©nial", "formidable", "excellent", "parfait", "top",
            "incroyable", "fantastique", "extraordinaire", "magnifique",

            # Verbes et actions
            "adore", "kiffe", "aime", "jubile", "rayonne", "p√©tille",

            # Expressions fran√ßaises
            "au top", "trop bien", "trop cool", "la f√™te", "au taquet",
            "de bonne humeur", "bonne nouvelle", "chanceux", "b√©ni",

            # √âmotions li√©es
            "fier", "satisfait", "triomphant", "victorieux", "chanceux",
            "soulag√©", "apais√©", "serein", "zen",

            # Familier
            "ouf", "styl√©", "mortel", "de ouf", "trop styl√©"
        },

        "sadness": {
            # Mots de base
            "triste", "malheureux", "d√©prim√©", "abattu", "d√©courag√©",
            "d√©sesp√©r√©", "chagrin√©", "m√©lancolique", "morose", "sombre",

            # Intensit√©s fortes
            "d√©vast√©", "an√©anti", "effondr√©", "bris√©", "d√©truit",
            "√©cras√©", "accabl√©", "tortur√©", "rong√©",

            # √âtats
            "mal", "pas bien", "vide", "seul", "isol√©", "abandonn√©",
            "rejet√©", "incompris", "paum√©", "perdu", "d√©sempar√©",

            # Verbes
            "pleure", "souffre", "morfle", "gal√®re", "d√©guste",

            # Expressions fran√ßaises
            "coup dur", "mauvaise passe", "fond du trou", "ras le bol",
            "en avoir marre", "plus le moral", "noir", "sombre p√©riode",

            # Familier
            "√† plat", "au fond du trou", "d√©go√ªt√©", "d√©pit√©", "blas√©",
            "lessiv√©", "dans le coaltar", "au bout du rouleau"
        },

        "anger": {
            # Mots de base
            "col√®re", "√©nerv√©", "furieux", "irrit√©", "agac√©", "exasp√©r√©",
            "outr√©", "r√©volt√©", "indign√©", "courrouc√©", "rageur",

            # Intensit√©s fortes
            "furibond", "enrag√©", "hors de moi", "bouillonne", "fulmine",
            "temp√™te", "explose", "p√®te un c√¢ble", "p√®te un plomb",

            # √âtats
            "frustr√©", "contrari√©", "vex√©", "bless√©", "amer", "rancunier",

            # Expressions morales
            "injuste", "inadmissible", "scandaleux", "r√©voltant",
            "inacceptable", "honteux", "indigne", "choquant",

            # Verbes
            "√©nerve", "emmerde", "gonfle", "saoule", "gave", "insupporte",

            # Expressions fran√ßaises
            "en avoir ras le bol", "√† bout", "satur√©", "gonfl√© √† bloc",
            "bout de nerfs", "rouge de col√®re", "monte au cr√©neau",

            # Familier
            "chiant", "relou", "gonflant", "saoulant", "lourd",
            "fait chier", "p√®te un c√¢ble", "en rogne", "sur les nerfs"
        },

        "fear": {
            # Mots de base
            "peur", "anxieux", "angoiss√©", "inquiet", "stress√©", "tendu",
            "nerveux", "craintif", "apeur√©", "effray√©", "terroris√©",

            # Intensit√©s fortes
            "paniqu√©", "horrifi√©", "√©pouvant√©", "affol√©", "mort de trouille",
            "paralys√©", "t√©tanis√©", "glac√©", "fig√©",

            # √âtats
            "mal √† l'aise", "mal au ventre", "boule au ventre",
            "n≈ìud √† l'estomac", "c≈ìur qui bat", "mains moites",

            # Phobies
            "phobique", "claustrophobe", "agoraphobe", "phobie",

            # Expressions
            "trouille", "flippe", "angoisse", "stress", "trac",
            "p√©toche", "frousse", "trouillard", "flippe sa race",

            # Familier
            "flipp√©", "stress√© √† mort", "mal", "pas rassur√©",
            "chie dans son froc", "fait dans son froc"
        },

        "surprise": {
            # Mots de base
            "surpris", "√©tonn√©", "stup√©fait", "abasourdi", "sid√©r√©",
            "√©bahi", "m√©dus√©", "interdit", "bouche b√©e",

            # Expressions
            "choc", "inattendu", "impr√©vu", "incroyable", "inimaginable",
            "impensable", "inesp√©r√©", "dingue", "fou",

            # Verbes
            "hallucine", "croit pas", "tombe des nues", "pas possible",

            # Familier
            "wahou", "oh", "ah", "quoi", "s√©rieux", "sans blague",
            "pas vrai", "c'est pas vrai", "jamais vu √ßa"
        },

        "disgust": {
            # Mots de base
            "d√©go√ªt", "r√©pugn√©", "√©c≈ìur√©", "d√©go√ªt√©", "r√©vuls√©",
            "naus√©eux", "malade", "immonde", "ignoble",

            # Moral
            "hypocrite", "malhonn√™te", "sale", "pourri", "corrompu",
            "menteur", "tra√Ætre", "l√¢che", "m√©prisable",

            # Physique
            "d√©gueulasse", "r√©pugnant", "infect", "ignoble", "immonde",
            "puant", "crade", "sale", "pourri", "moisi",

            # Expressions
            "√ßa me d√©go√ªte", "me fait gerber", "envie de vomir",
            "me soul√®ve le c≈ìur", "horrible", "atroce",

            # Familier
            "d√©geu", "crade", "cracra", "d√©gueu", "beurk", "berk",
            "gerbe", "vomi"
        },

        # √âMOTIONS COMPLEXES (ajout√©es selon demande team)
        "frustration": {
            "frustr√©", "contrari√©", "irrit√©", "agac√©", "emb√™t√©",
            "bloqu√©", "coinc√©", "emp√™ch√©", "entrav√©", "limit√©",
            "bug", "plante", "marche pas", "fonctionne pas",
            "gal√®re", "rame", "patauge", "n'y arrive pas"
        },

        "relief": {
            "soulag√©", "ouf", "enfin", "lib√©r√©", "d√©livr√©", "apais√©",
            "rassur√©", "tranquille", "serein", "fini", "termin√©",
            "pass√©", "derri√®re moi", "r√©gl√©"
        },

        "determination": {
            "d√©termin√©", "motiv√©", "d√©cid√©", "r√©solu", "tenace",
            "obstin√©", "pers√©v√©rant", "acharn√©", "volontaire",
            "vais y arriver", "r√©ussirai", "me bats", "l√¢che rien",
            "continue", "abandonne pas"
        },

        "pride": {
            "fier", "orgueilleux", "satisfait", "content de moi",
            "accompli", "r√©ussi", "gagn√©", "triomph√©", "excellent",
            "bien fait", "chapeau", "bravo √† moi"
        },

        "shame": {
            "honte", "honteux", "embarrass√©", "g√™n√©", "confus",
            "humili√©", "mortifi√©", "ridicule", "path√©tique",
            "nul", "minable", "rat√©", "merd√©"
        },

        "guilt": {
            "coupable", "culpabilis√©", "fautif", "responsable",
            "ma faute", "mon erreur", "regret", "regrette",
            "aurais d√ª", "pas d√ª", "remords"
        },

        "loneliness": {
            "seul", "isol√©", "solitaire", "abandonn√©", "d√©laiss√©",
            "exclu", "rejet√©", "mis de c√¥t√©", "oubli√©",
            "personne", "aucun ami", "tout seul"
        },

        "overwhelmed": {
            "d√©bord√©", "submerg√©", "d√©pass√©", "satur√©", "√† bout",
            "trop", "trop de", "tout en m√™me temps", "plus capable",
            "n'y arrive plus", "craque", "trop pour moi"
        }
    }

    # ===== STOPLIST (FAUX POSITIFS) =====
    # Conseil Grok : mots qui ressemblent √† des √©motions mais ne le sont pas en contexte

    STOPLIST = {
        "chaud",  # "c'est chaud" = difficile, pas col√®re
        "cool",   # peut √™tre ironique
        "mort",   # "mort de rire" ‚â† tristesse
        "malade", # "c'est malade" = g√©nial en slang
        "dingue", # "c'est dingue" = surprenant mais pas n√©gatif
        "fou",    # "c'est fou" = neutre/positif souvent
    }

    # ===== SHIFTERS =====

    NEGATIONS = {
        "pas", "plus", "jamais", "aucun", "aucune", "rien",
        "nullement", "gu√®re", "ne", "n'", "non"
    }

    INTENSIFIERS = {
        "tr√®s", "trop", "super", "hyper", "ultra", "m√©ga",
        "extr√™mement", "vraiment", "tellement", "grave",
        "carr√©ment", "compl√®tement", "totalement", "absolument"
    }

    ATTENUATORS = {
        "un peu", "l√©g√®rement", "plut√¥t", "assez", "moyennement",
        "quelque peu", "vaguement", "√† peine"
    }

    # ===== PATTERNS FRAN√áAIS =====
    # Conseil GPT/Marc : expressions contextuelles fran√ßaises

    EMOTION_PATTERNS = [
        # Structure : (regex, √©motion, intensit√©_bonus)
        (r"je suis (\\w+)", None, 0.1),  # None = d√©terminer par le mot
        (r"je me sens (\\w+)", None, 0.1),
        (r"√ßa me rend (\\w+)", None, 0.15),
        (r"√ßa me fait (\\w+)", None, 0.1),
        (r"j'ai peur", "fear", 0.2),
        (r"j'ai la trouille", "fear", 0.3),
        (r"√ßa m'angoisse", "fear", 0.2),
        (r"√ßa me d√©go√ªte", "disgust", 0.2),
        (r"√ßa m'√©nerve", "anger", 0.2),
        (r"√ßa me so√ªle", "anger", 0.2),
        (r"je suis soulag√©", "relief", 0.2),
        (r"ouf", "relief", 0.15),
    ]

    # ===== EMOJI MAPPING =====
    # Conseil team : mapping direct √©mojis

    EMOJI_MAP = {
        "üòä": ("joy", 0.1),
        "üòÉ": ("joy", 0.15),
        "üòÑ": ("joy", 0.15),
        "üòÅ": ("joy", 0.15),
        "üéâ": ("joy", 0.2),
        "ü•≥": ("joy", 0.2),
        "üòç": ("joy", 0.2),
        "ü§©": ("joy", 0.2),

        "üò¢": ("sadness", 0.2),
        "üò≠": ("sadness", 0.3),
        "üòû": ("sadness", 0.15),
        "üòî": ("sadness", 0.15),
        "üíî": ("sadness", 0.2),

        "üò†": ("anger", 0.2),
        "üò°": ("anger", 0.3),
        "ü§¨": ("anger", 0.3),
        "üí¢": ("anger", 0.2),

        "üò±": ("fear", 0.3),
        "üò∞": ("fear", 0.2),
        "üò®": ("fear", 0.2),
        "ü•∂": ("fear", 0.15),

        "üòÆ": ("surprise", 0.15),
        "üò≤": ("surprise", 0.2),
        "ü§Ø": ("surprise", 0.25),

        "ü§¢": ("disgust", 0.2),
        "ü§Æ": ("disgust", 0.3),
        "ü§ß": ("disgust", 0.15),

        "üòå": ("relief", 0.15),
        "üòÖ": ("relief", 0.1),
    }

    def __init__(self):
        """Initialise le d√©tecteur"""
        # Cr√©er l'index invers√© pour recherche rapide
        self.word_to_emotions: Dict[str, Set[str]] = {}
        for emotion, words in self.EMOTION_LEXICON.items():
            for word in words:
                if word not in self.word_to_emotions:
                    self.word_to_emotions[word] = set()
                self.word_to_emotions[word].add(emotion)

    def detect(self, text: str) -> EmotionResult:
        """
        D√©tecte l'√©motion dans un texte.

        Args:
            text: Texte √† analyser

        Returns:
            EmotionResult avec primary, secondary, intensity, cues, scores
        """
        text_lower = text.lower()
        tokens = text_lower.split()

        # Scores par √©motion
        emotion_scores: Dict[str, float] = {emotion: 0.0 for emotion in self.EMOTION_LEXICON.keys()}
        cues: List[str] = []

        # 1. D√âTECTION LEXICALE avec shifters
        for i, token in enumerate(tokens):
            # Nettoyer ponctuation
            clean_token = re.sub(r'[^\\w\\s]', '', token)

            # Skip stoplist
            if clean_token in self.STOPLIST:
                continue

            # Chercher le mot dans le lexique
            if clean_token in self.word_to_emotions:
                emotions = self.word_to_emotions[clean_token]

                # Fen√™tre de n√©gation (¬±3 tokens selon Grok)
                negation_window_start = max(0, i - 3)
                negation_window = tokens[negation_window_start:i]

                has_negation = any(neg in " ".join(negation_window) for neg in self.NEGATIONS)

                # Intensificateur dans la fen√™tre
                has_intensifier = any(intens in " ".join(negation_window) for intens in self.INTENSIFIERS)
                has_attenuator = any(atten in " ".join(negation_window) for atten in self.ATTENUATORS)

                for emotion in emotions:
                    # Score de base
                    score = 1.0

                    # Appliquer shifters
                    if has_negation:
                        score *= -0.5  # Inversion partielle
                        cues.append(f"n√©gation: '{token}'")
                    elif has_intensifier:
                        score *= 1.5
                        cues.append(f"intensif: '{token}'")
                    elif has_attenuator:
                        score *= 0.5
                        cues.append(f"att√©nu√©: '{token}'")
                    else:
                        cues.append(f"mot: '{token}'")

                    emotion_scores[emotion] += score

        # 2. PATTERNS FRAN√áAIS
        for pattern, emotion_hint, bonus in self.EMOTION_PATTERNS:
            matches = re.findall(pattern, text_lower)
            if matches:
                if emotion_hint:
                    emotion_scores[emotion_hint] += bonus
                    cues.append(f"pattern: '{pattern}'")
                else:
                    # D√©terminer l'√©motion par le mot captur√©
                    for match in matches:
                        if match in self.word_to_emotions:
                            for emo in self.word_to_emotions[match]:
                                emotion_scores[emo] += bonus
                                cues.append(f"pattern+mot: '{match}'")

        # 3. √âMOJIS
        for emoji, (emotion, bonus) in self.EMOJI_MAP.items():
            if emoji in text:
                emotion_scores[emotion] += bonus
                cues.append(f"emoji: {emoji}")

        # 4. PONCTUATION & CAPS
        exclamation_count = text.count("!")
        if exclamation_count > 0:
            # Booster les √©motions fortes d√©tect√©es
            for emotion in emotion_scores:
                if emotion_scores[emotion] > 0:
                    emotion_scores[emotion] += exclamation_count * 0.1
            cues.append(f"exclam: {exclamation_count}")

        # CAPS (mots en majuscules)
        caps_count = sum(1 for word in text.split() if word.isupper() and len(word) > 2)
        if caps_count > 0:
            for emotion in emotion_scores:
                if emotion_scores[emotion] > 0:
                    emotion_scores[emotion] += caps_count * 0.1
            cues.append(f"CAPS: {caps_count}")

        # 5. D√âTERMINER PRIMARY & SECONDARY
        # Trier par score
        sorted_emotions = sorted(emotion_scores.items(), key=lambda x: x[1], reverse=True)

        # Si tous les scores sont <= 0, c'est neutral
        if sorted_emotions[0][1] <= 0:
            return EmotionResult(
                primary="neutral",
                secondary=[],
                intensity=0.5,
                cues=["aucun signal √©motionnel d√©tect√©"],
                scores=emotion_scores
            )

        primary_emotion, primary_score = sorted_emotions[0]

        # Secondary : √©motions avec score > 0.6 * primary_score
        secondary = [
            emotion for emotion, score in sorted_emotions[1:]
            if score > 0.6 * primary_score and score > 0
        ]

        # 6. CALCULER INTENSIT√â
        # Intensit√© bas√©e sur le score normalis√© + clamped [0.15-0.95] (conseil Grok)
        raw_intensity = primary_score / 10.0  # Normalisation basique

        # Sigmoid pour smooth
        intensity = 1 / (1 + (2.71828 ** (-raw_intensity)))

        # Clamp [0.15 - 0.95]
        intensity = max(0.15, min(0.95, intensity))

        return EmotionResult(
            primary=primary_emotion,
            secondary=secondary[:2],  # Max 2 secondaires
            intensity=intensity,
            cues=cues,
            scores=emotion_scores
        )


# ===============================================================================
# TESTS UNITAIRES BASIQUES
# ===============================================================================

def test_emotion_detector_v2():
    """Tests basiques du d√©tecteur"""
    detector = EmotionDetectorV2()

    # Test 1 : Joie simple
    result = detector.detect("Je suis trop content !")
    assert result.primary == "joy", f"Expected joy, got {result.primary}"
    assert result.intensity > 0.5
    print(f"‚úÖ Test 1 (joie) : {result.primary} @ {result.intensity:.2f}")

    # Test 2 : Tristesse
    result = detector.detect("Je suis vraiment triste...")
    assert result.primary == "sadness", f"Expected sadness, got {result.primary}"
    print(f"‚úÖ Test 2 (tristesse) : {result.primary} @ {result.intensity:.2f}")

    # Test 3 : N√©gation
    result = detector.detect("Je ne suis pas content du tout")
    # Devrait d√©tecter une √©motion n√©gative ou neutre, pas joy
    assert result.primary != "joy", f"Negation failed, got {result.primary}"
    print(f"‚úÖ Test 3 (n√©gation) : {result.primary} @ {result.intensity:.2f}")

    # Test 4 : Frustration (√©motion complexe)
    result = detector.detect("Je suis frustr√©, √ßa marche pas !")
    assert result.primary == "frustration" or "frustration" in result.secondary
    print(f"‚úÖ Test 4 (frustration) : {result.primary} @ {result.intensity:.2f}")

    # Test 5 : √âmojis
    result = detector.detect("Trop bien ! üéâüòä")
    assert result.primary == "joy"
    assert any("emoji" in cue for cue in result.cues)
    print(f"‚úÖ Test 5 (√©mojis) : {result.primary} @ {result.intensity:.2f}, cues: {result.cues}")

    print("\\n‚úÖ Tous les tests de base passent !")


if __name__ == "__main__":
    print("üß™ Tests unitaires EmotionDetectorV2...")
    print()
    test_emotion_detector_v2()
'''

# √âcrire le fichier
emotion_detector_file = SRC_DIR / "nlp" / "emotion_detector_v2.py"
with open(emotion_detector_file, 'w', encoding='utf-8') as f:
    f.write(emotion_detector_code)

print(f"‚úÖ Fichier cr√©√© : {emotion_detector_file}")
print()

# ===============================================================================
# √âTAPE 2 : CR√âATION DE hybrid_searcher.py
# ===============================================================================

print("üìù [2/5] Cr√©ation de src/jeffrey/search/hybrid_searcher.py...")
print()

hybrid_searcher_code = '''"""
JEFFREY OS - Recherche Hybride
===============================

Recherche combinant :
- BM25 (lexical)
- TF-IDF (lexical)
- Normalisation min-max
- Explicabilit√© (weights_used, components)

Sprint 1 : Version basique sans embeddings
Sprint 2 : Ajout embeddings s√©mantiques

√âquipe : Dream Team Jeffrey OS
"""

from typing import List, Dict, Any, Tuple
from dataclasses import dataclass
from collections import Counter
import math


@dataclass
class SearchResult:
    """R√©sultat de recherche avec explicabilit√©"""
    content: str
    score: float
    index: int
    components: Dict[str, float]  # {'lexical': 0.8, 'recency': 0.2}
    weights_used: Dict[str, float]  # {'w_lex': 0.6, 'w_time': 0.4}


class HybridSearcher:
    """
    Recherche hybride pour Jeffrey OS.

    Sprint 1 : BM25 + normalisation
    Sprint 2 : + embeddings s√©mantiques
    """

    def __init__(
        self,
        w_lexical: float = 0.6,
        w_recency: float = 0.4
    ):
        """
        Initialise le chercheur.

        Args:
            w_lexical: Poids lexical (BM25)
            w_recency: Poids r√©cence
        """
        self.w_lexical = w_lexical
        self.w_recency = w_recency

        # Cache
        self.documents: List[str] = []
        self.doc_lengths: List[int] = []
        self.avg_doc_length: float = 0.0
        self.idf_cache: Dict[str, float] = {}

    def add_documents(self, documents: List[str]):
        """Indexe des documents pour recherche"""
        self.documents = documents
        self.doc_lengths = [len(doc.split()) for doc in documents]
        self.avg_doc_length = sum(self.doc_lengths) / len(self.doc_lengths) if documents else 0

        # Calculer IDF
        self._compute_idf()

    def _compute_idf(self):
        """Calcule IDF (Inverse Document Frequency)"""
        N = len(self.documents)
        if N == 0:
            return

        # Compter dans combien de docs chaque terme appara√Æt
        term_doc_count: Dict[str, int] = {}

        for doc in self.documents:
            terms = set(doc.lower().split())
            for term in terms:
                term_doc_count[term] = term_doc_count.get(term, 0) + 1

        # IDF = log((N - df + 0.5) / (df + 0.5) + 1)
        for term, df in term_doc_count.items():
            self.idf_cache[term] = math.log((N - df + 0.5) / (df + 0.5) + 1.0)

    def _bm25_score(self, query: str, doc: str, doc_length: int) -> float:
        """
        Calcule le score BM25.

        BM25 = sum(IDF(qi) * (f(qi, D) * (k1 + 1)) / (f(qi, D) + k1 * (1 - b + b * |D| / avgdl)))

        o√π :
        - qi = terme de la query
        - f(qi, D) = fr√©quence du terme dans le doc
        - |D| = longueur du doc
        - avgdl = longueur moyenne des docs
        - k1 = 1.5 (param√®tre)
        - b = 0.75 (param√®tre)
        """
        k1 = 1.5
        b = 0.75

        query_terms = query.lower().split()
        doc_terms = doc.lower().split()
        doc_term_freq = Counter(doc_terms)

        score = 0.0

        for term in query_terms:
            if term not in self.idf_cache:
                continue

            idf = self.idf_cache[term]
            tf = doc_term_freq.get(term, 0)

            numerator = tf * (k1 + 1)
            denominator = tf + k1 * (1 - b + b * (doc_length / self.avg_doc_length))

            score += idf * (numerator / denominator)

        return score

    def _normalize_scores(self, scores: List[float]) -> List[float]:
        """Normalisation min-max vers [0, 1]"""
        if not scores or max(scores) == min(scores):
            return [0.5] * len(scores)

        min_score = min(scores)
        max_score = max(scores)
        range_score = max_score - min_score

        return [(s - min_score) / range_score for s in scores]

    def search(
        self,
        query: str,
        top_k: int = 5,
        recency_scores: List[float] = None
    ) -> List[SearchResult]:
        """
        Recherche hybride.

        Args:
            query: Requ√™te de recherche
            top_k: Nombre de r√©sultats
            recency_scores: Scores de r√©cence [0-1] pour chaque doc (optionnel)

        Returns:
            Liste de SearchResult tri√©e par pertinence
        """
        if not self.documents:
            return []

        # 1. SCORES LEXICAUX (BM25)
        lexical_scores = []
        for i, doc in enumerate(self.documents):
            score = self._bm25_score(query, doc, self.doc_lengths[i])
            lexical_scores.append(score)

        # Normaliser
        lexical_normalized = self._normalize_scores(lexical_scores)

        # 2. SCORES DE R√âCENCE
        if recency_scores is None:
            # Par d√©faut, r√©cence uniforme
            recency_normalized = [0.5] * len(self.documents)
        else:
            recency_normalized = recency_scores  # D√©j√† normalis√©s [0-1]

        # 3. FUSION POND√âR√âE
        results = []

        for i, doc in enumerate(self.documents):
            lex_score = lexical_normalized[i]
            rec_score = recency_normalized[i]

            # Score final
            final_score = (
                self.w_lexical * lex_score +
                self.w_recency * rec_score
            )

            result = SearchResult(
                content=doc,
                score=final_score,
                index=i,
                components={
                    "lexical": lex_score,
                    "recency": rec_score
                },
                weights_used={
                    "w_lexical": self.w_lexical,
                    "w_recency": self.w_recency
                }
            )

            results.append(result)

        # Trier par score d√©croissant
        results.sort(key=lambda x: x.score, reverse=True)

        return results[:top_k]


# ===============================================================================
# TESTS UNITAIRES
# ===============================================================================

def test_hybrid_searcher():
    """Tests basiques du chercheur hybride"""
    searcher = HybridSearcher(w_lexical=0.7, w_recency=0.3)

    documents = [
        "J'aime programmer en Python",
        "Python est mon langage pr√©f√©r√©",
        "J'adore le JavaScript",
        "Le caf√© est d√©licieux",
        "Je bois du caf√© tous les matins"
    ]

    searcher.add_documents(documents)

    # Test 1 : Recherche Python
    results = searcher.search("Python", top_k=2)
    assert len(results) == 2
    assert "Python" in results[0].content or "python" in results[0].content.lower()
    print(f"‚úÖ Test 1 (Python) : Top result = \\"{results[0].content[:50]}...\\"")
    print(f"   Score: {results[0].score:.3f}, Components: {results[0].components}")

    # Test 2 : Recherche caf√©
    results = searcher.search("caf√©", top_k=2)
    assert len(results) == 2
    print(f"‚úÖ Test 2 (caf√©) : Top result = \\"{results[0].content[:50]}...\\"")

    # Test 3 : Explicabilit√©
    results = searcher.search("test", top_k=1)
    assert "weights_used" in results[0].__dict__
    assert "components" in results[0].__dict__
    print(f"‚úÖ Test 3 (explicabilit√©) : weights={results[0].weights_used}")

    print("\\n‚úÖ Tous les tests HybridSearcher passent !")


if __name__ == "__main__":
    print("üß™ Tests unitaires HybridSearcher...")
    print()
    test_hybrid_searcher()
'''

# √âcrire le fichier
hybrid_searcher_file = SRC_DIR / "search" / "hybrid_searcher.py"
with open(hybrid_searcher_file, 'w', encoding='utf-8') as f:
    f.write(hybrid_searcher_code)

print(f"‚úÖ Fichier cr√©√© : {hybrid_searcher_file}")
print()

# ===============================================================================
# √âTAPE 3-5 : Instructions pour la suite
# ===============================================================================

print("=" * 80)
print("üéâ SPRINT 1 - FICHIERS CR√â√âS AVEC SUCC√àS !")
print("=" * 80)
print()
print("‚úÖ Fichiers cr√©√©s :")
print(f"   1. {emotion_detector_file}")
print(f"   2. {hybrid_searcher_file}")
print()
print("üß™ PROCHAINES √âTAPES :")
print()
print("1. Tester EmotionDetectorV2 :")
print(f"   python3 {emotion_detector_file}")
print()
print("2. Tester HybridSearcher :")
print(f"   python3 {hybrid_searcher_file}")
print()
print("3. Int√©grer dans runner_convos_simple.py :")
print("   - Remplacer SimpleEmotionDetector par EmotionDetectorV2")
print("   - Ajouter HybridSearcher pour la recherche m√©moire")
print("   - Adapter la lecture des YAML (conversation/validation)")
print()
print("4. Lancer les 40 sc√©narios :")
print("   python3 tests/runner_convos_simple.py")
print()
print("5. Analyser les r√©sultats :")
print("   - Viser Macro-F1 ‚â• 0.70")
print("   - MRR@5 ‚â• 0.65")
print("   - Latence p95 ‚â§ 500ms")
print()
print("üìä OBJECTIF SPRINT 1 : Passer de 39.9% ‚Üí 70%+ de r√©ussite")
print()
print("=" * 80)
print("üî• SPRINT 1 READY TO GO ! LET'S CRUSH IT ! üöÄ")
print("=" * 80)
