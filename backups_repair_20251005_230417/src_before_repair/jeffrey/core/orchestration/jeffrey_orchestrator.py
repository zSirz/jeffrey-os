#!/usr/bin/env python3
"""
üß† JEFFREY V1 - ORCHESTRATEUR CENTRAL V2

Orchestrateur principal avec impl√©mentation compl√®te des 8 m√©thodes critiques :
- Pattern LoaderMixin unifi√©
- Context Builder s√©curis√© et optimis√©
- Gestion robuste des erreurs
- Tests et m√©triques int√©gr√©s

Version: 2.0 (Production-Ready)
"""

from __future__ import annotations

import asyncio
import hashlib
import json
import logging
import os
import re
import sys
import time
from datetime import datetime
from functools import lru_cache
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

# Import des composants internes
from .orchestrator_components import (AdaptiveContextStrategy, ComponentInfo,
                                      ComponentLoadError, ComponentStatus,
                                      ConfigError, ContextSanitizer,
                                      ConversationContext, Intent, LoaderMixin,
                                      Message, MessageImportanceAnalyzer,
                                      OrchestratorError, ValidationError)

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# ============================================================================
# ORCHESTRATEUR PRINCIPAL
# ============================================================================


class JeffreyOrchestrator(LoaderMixin):
    """
    Jeffrey V1 Central Orchestrator - Version Production

    Fonctionnalit√©s principales :
    - Chargement s√©curis√© de tous les composants
    - Construction de contexte intelligent et s√©curis√©
    - Gestion robuste des erreurs et fallbacks
    - M√©triques et monitoring int√©gr√©s
    """

    def __init__(self, config=None) -> None:
        """Initialize Jeffrey V1 orchestrator"""
        super().__init__()

        logger.info("üöÄ Initializing Jeffrey V1 Orchestrator V2...")

        # Configuration
        self.config = config or self._load_default_config()

        # Initialisers de composants
        self.sanitizer = ContextSanitizer()
        self.strategy_manager = AdaptiveContextStrategy()
        self.importance_analyzer = MessageImportanceAnalyzer()

        # Caches et m√©triques
        self._context_cache = {}
        self._performance_metrics = {
            "calls": 0,
            "errors": 0,
            "avg_response_time": 0,
            "total_response_time": 0,
            "cache_hits": 0,
            "cache_misses": 0,
        }

        # √âtat de l'orchestrateur
        self._initialized = False
        self._health_status = True
        self._last_health_check = None

        # Initialize core modules
        self._initialize_modules()

    def _load_default_config(self) -> Any:
        """Charge la configuration par d√©faut"""
        try:
            from utils.secure_config import SecureConfig

            return SecureConfig()
        except ImportError:
            logger.warning("SecureConfig not available, using minimal config")

            # Configuration minimale
            class MinimalConfig:
    """
    Classe MinimalConfig pour le syst√®me Jeffrey OS.

    Cette classe impl√©mente les fonctionnalit√©s sp√©cifiques n√©cessaires
    au bon fonctionnement du module. Elle g√®re l'√©tat interne, les transformations
    de donn√©es, et l'interaction avec les autres composants du syst√®me.
    """
                def get(self, key, default=None):
                    return os.getenv(key, default)

                def __getattr__(self, name):
                    return os.getenv(name.upper())

            return MinimalConfig()

    def _initialize_modules(self):
        """Initialize Jeffrey's core modules"""
        logger.info("üì¶ Loading core modules...")

        # 1. Secrets Manager
        self._load_secrets_manager()

        # 2. Memory Manager
        self._load_memory_manager()

        # 3. GPT Connector
        self._load_gpt_connector()

        # 4. Voice Engine
        self._load_voice_engine()

        # Summary
        loaded_components = sum(
            1
            for comp in self._components.values()
            if comp.status == ComponentStatus.LOADED
        )
        total_components = len(self._components)

        logger.info(f"üìä Modules loaded: {loaded_components}/{total_components}")

        self._initialized = True
        self._last_health_check = datetime.now()

    # ========================================================================
    # M√âTHODES LOADER (7 m√©thodes critiques)
    # ========================================================================

    def _load_secrets_manager(self) -> Optional[Any]:
        """
        Charge le gestionnaire de secrets avec support du mode bypass.

        Returns:
            SecretsManager instance ou SecureConfig si bypass activ√©
        """
        try:
            # V√©rifier si le mode bypass est activ√©
            bypass_mode = (
                hasattr(self.config, "bypass_secrets") and self.config.bypass_secrets
            ) or os.getenv("JEFFREY_BYPASS_SECRETS", "false").lower() == "true"

            if bypass_mode:
                logger.info("üîì Secrets manager in bypass mode (using SecureConfig)")
                from utils.secure_config import SecureConfig

                return self._load_component(
                    component_name="secrets_manager",
                    component_class=SecureConfig,
                    config_key="security",
                    validate_on_load=False,
                    fallback_instance=SecureConfig(),
                )
            else:
                # Mode normal avec SecretsManager chiffr√©
                from security.secrets_manager import SecretsManager

                return self._load_component(
                    component_name="secrets_manager",
                    component_class=SecretsManager,
                    config_key="security",
                    validate_on_load=False,  # Validation diff√©r√©e pour les secrets
                    encryption_enabled=True,
                )

        except ImportError as e:
            logger.warning(
                f"SecretsManager not available: {e}, falling back to SecureConfig"
            )
            try:
                from utils.secure_config import SecureConfig

                fallback = SecureConfig()
                setattr(self, "_secrets_manager", fallback)
                return fallback
            except ImportError:
                logger.error("No configuration system available")
                return None
        except Exception as e:
            logger.error(f"Failed to load secrets manager: {e}")
            return None

    def _load_memory_manager(self) -> Optional[Any]:
        """
        Charge le gestionnaire de m√©moire.

        Returns:
            MemoryManager instance ou None si √©chec
        """
        try:
            from core.memory_manager import MemoryManager

            return self._load_component(
                component_name="memory_manager",
                component_class=MemoryManager,
                config_key="memory",
                validate_on_load=True,
                max_memory_mb=self.config.get("max_memory_mb", 100),
                compression_enabled=True,
                persistence_enabled=True,
            )

        except ImportError as e:
            logger.warning(f"MemoryManager not available: {e}")

            # Cr√©er un memory manager mock pour les tests
            class MockMemoryManager:
    """
    Classe MockMemoryManager pour le syst√®me Jeffrey OS.

    Cette classe impl√©mente les fonctionnalit√©s sp√©cifiques n√©cessaires
    au bon fonctionnement du module. Elle g√®re l'√©tat interne, les transformations
    de donn√©es, et l'interaction avec les autres composants du syst√®me.
    """
                def __init__(self) -> None:
                    self._memory = {}

                def add_to_context(self, message, user_id, response=None):
                    if user_id not in self._memory:
                        self._memory[user_id] = []
                    self._memory[user_id].append(
                        {
                            "message": message,
                            "response": response,
                            "timestamp": datetime.now(),
                        }
                    )

                def get_context(self, user_id) -> Any:
                    return self._memory.get(user_id, [])

                def store(self, key, data, ttl=None):
                    return True

                def compress(self, data):
                    return data

                def validate(self):
                    return True

                def health_check(self):
                    return True

            mock_manager = MockMemoryManager()
            setattr(self, "_memory_manager", mock_manager)
            logger.info("‚úÖ Using mock memory manager")
            return mock_manager

        except Exception as e:
            logger.error(f"Failed to load memory manager: {e}")
            return None

    def _load_gpt_connector(self) -> Optional[Any]:
        """
        Charge le connecteur GPT/OpenAI avec gestion robuste des cl√©s API.

        Returns:
            GPTConnector instance ou None si √©chec
        """
        try:
            # R√©cup√©rer la cl√© API depuis plusieurs sources
            api_key = None

            # 1. Variable d'environnement directe
            api_key = os.getenv("OPENAI_API_KEY")

            # 2. Depuis le secrets manager si disponible
            if (
                not api_key
                and hasattr(self, "_secrets_manager")
                and self._secrets_manager
            ):
                try:
                    if hasattr(self._secrets_manager, "get"):
                        api_key = self._secrets_manager.get(
                            "OPENAI_API_KEY", required=False
                        )
                    elif hasattr(self._secrets_manager, "get_secret"):
                        api_key = self._secrets_manager.get_secret("OPENAI_API_KEY")
                except Exception as e:
                    logger.warning(f"Failed to get API key from secrets manager: {e}")

            # 3. Depuis la config
            if not api_key and self.config:
                api_key = getattr(self.config, "OPENAI_API_KEY", None)

            if not api_key or len(api_key) < 20:
                raise ConfigError("No valid OpenAI API key found")

            # Cr√©er le connecteur GPT
            from openai import OpenAI

            class GPTConnector:
    """
    Classe GPTConnector pour le syst√®me Jeffrey OS.

    Cette classe impl√©mente les fonctionnalit√©s sp√©cifiques n√©cessaires
    au bon fonctionnement du module. Elle g√®re l'√©tat interne, les transformations
    de donn√©es, et l'interaction avec les autres composants du syst√®me.
    """
                def __init__(self, api_key: str) -> None:
                    self.client = OpenAI(api_key=api_key)
                    self._api_key_preview = f"{api_key[:10]}...{api_key[-4:]}"

                async def generate_response(
                    self, prompt: str, context: Dict = None
                ) -> str:
                    """Generate response using OpenAI API"""
                    try:
                        messages = [
                            {
                                "role": "system",
                                "content": "You are Jeffrey, a helpful AI assistant with a friendly and empathetic personality. You provide thoughtful, accurate responses while maintaining a warm conversational tone.",
                            },
                            {"role": "user", "content": prompt},
                        ]

                        if context:
                            context_msg = f"Additional context: {json.dumps(context, ensure_ascii=False)}"
                            messages.insert(
                                1, {"role": "system", "content": context_msg}
                            )

                        response = await asyncio.to_thread(
                            self.client.chat.completions.create,
                            model="gpt-3.5-turbo",
                            messages=messages,
                            temperature=0.7,
                            max_tokens=800,
                            top_p=1,
                            frequency_penalty=0,
                            presence_penalty=0,
                        )

                        if response and response.choices:
                            return response.choices[0].message.content
                        else:
                            return "I couldn't generate a proper response."

                    except Exception as e:
                        logger.error(f"GPT API error: {e}")
                        return f"I encountered a technical issue: {str(e)}"

                def validate(self):
                    """Valide la connexion OpenAI"""
                    try:
                        # Test simple avec un prompt minimal
                        test_response = self.client.chat.completions.create(
                            model="gpt-3.5-turbo",
                            messages=[{"role": "user", "content": "Hi"}],
                            max_tokens=5,
                        )
                        return bool(test_response and test_response.choices)
                    except Exception as e:
                        logger.error(f"GPT validation failed: {e}")
                        return False

                def health_check(self):
                    """Health check pour le connecteur"""
                    try:
                        # V√©rification de la connectivit√©
                        models = self.client.models.list()
                        return bool(models and models.data)
                    except Exception:
                        return False

            gpt_connector = GPTConnector(api_key)
            setattr(self, "_gpt_connector", gpt_connector)

            logger.info(
                f"‚úÖ GPT Connector loaded with API key: {gpt_connector._api_key_preview}"
            )
            return gpt_connector

        except ImportError as e:
            logger.error(f"OpenAI library not available: {e}")
            return None
        except ConfigError as e:
            logger.error(f"GPT configuration error: {e}")
            return None
        except Exception as e:
            logger.error(f"Failed to load GPT connector: {e}")
            return None

    def _load_voice_engine(self) -> Optional[Any]:
        """
        Charge le moteur de synth√®se vocale ElevenLabs.

        Returns:
            VoiceEngine instance ou None si √©chec
        """
        try:
            # R√©cup√©rer la cl√© API ElevenLabs
            api_key = None

            # Sources multiples pour la cl√© API
            if hasattr(self, "_secrets_manager") and self._secrets_manager:
                try:
                    if hasattr(self._secrets_manager, "get"):
                        api_key = self._secrets_manager.get(
                            "ELEVENLABS_API_KEY", required=False
                        )
                    elif hasattr(self._secrets_manager, "get_secret"):
                        api_key = self._secrets_manager.get_secret("ELEVENLABS_API_KEY")
                except Exception as e:
                    logger.warning(f"Failed to get ElevenLabs key from secrets: {e}")

            if not api_key:
                api_key = os.getenv("ELEVENLABS_API_KEY")

            if not api_key and self.config:
                api_key = getattr(self.config, "ELEVENLABS_API_KEY", None)

            if not api_key:
                logger.warning(
                    "No ElevenLabs API key found, voice engine will be disabled"
                )
                return None

            # Charger le VoiceEngine
            from voice.voice_engine import VoiceEngine

            voice_config = {
                "api_key": api_key,
                "cache_enabled": True,
                "cache_size_mb": 50,
                "default_voice_id": self.config.get(
                    "ELEVENLABS_VOICE_ID", "EXAVITQu4vr4xnSDxMaL"
                ),
            }

            return self._load_component(
                component_name="voice_engine",
                component_class=VoiceEngine,
                config_key="voice",
                validate_on_load=True,
                health_check_on_load=True,
                **voice_config,
            )

        except ImportError as e:
            logger.warning(f"VoiceEngine not available: {e}")
            return None
        except Exception as e:
            logger.error(f"Failed to load voice engine: {e}")
            return None

    def _detect_emotion_from_text(self, text: str) -> Dict[str, float]:
        """
        D√©tecte les √©motions dans un texte avec analyse de patterns.

        Args:
            text: Texte √† analyser

        Returns:
            Dict avec scores √©motionnels normalis√©s

        Example:
            >>> emotions = orchestrator._detect_emotion_from_text("I'm so happy!")
            >>> print(emotions['happy'])  # 0.8
        """
        if not text or not text.strip():
            return {"neutral": 1.0}

        try:
            # Cr√©er l'analyseur d'√©motions si pas encore fait
            if not hasattr(self, "_emotion_detector"):
                self._emotion_detector = self._create_emotion_detector()

            emotions = self._emotion_detector.analyze(text.lower())

            # Normaliser les scores pour qu'ils somment √† 1.0
            total_score = sum(emotions.values())
            if total_score > 0:
                emotions = {k: v / total_score for k, v in emotions.items()}

            logger.debug(f"Detected emotions for '{text[:30]}...': {emotions}")
            return emotions

        except Exception as e:
            logger.error(f"Emotion detection failed: {e}")
            return {"neutral": 1.0}  # Fallback s√ªr

    def _create_emotion_detector(self):
        """Cr√©e un d√©tecteur d'√©motion bas√© sur des patterns"""

        class EmotionDetector:
    """
    Classe EmotionDetector pour le syst√®me Jeffrey OS.

    Cette classe impl√©mente les fonctionnalit√©s sp√©cifiques n√©cessaires
    au bon fonctionnement du module. Elle g√®re l'√©tat interne, les transformations
    de donn√©es, et l'interaction avec les autres composants du syst√®me.
    """
            def __init__(self) -> None:
                self.emotion_patterns = {
                    "happy": [
                        r"\b(happy|joy|joyful|excited|great|wonderful|amazing|fantastic|excellent|love|perfect)\b",
                        r"\b(smile|laugh|lol|haha|üòä|üòÑ|üòÉ|üôÇ|üòç|ü•∞)\b",
                        r"[!]{2,}",  # Multiple exclamation marks
                    ],
                    "sad": [
                        r"\b(sad|depressed|down|upset|disappointed|hurt|cry|tears|üò¢|üò≠|‚òπÔ∏è|üôÅ)\b",
                        r"\b(terrible|awful|horrible|worst|hate)\b",
                    ],
                    "angry": [
                        r"\b(angry|mad|furious|annoyed|frustrated|irritated|pissed|rage|üò†|üò°|ü§¨)\b",
                        r"\b(stupid|damn|hell|fuck|shit)\b",
                    ],
                    "fearful": [
                        r"\b(scared|afraid|fear|worried|anxious|nervous|panic|terrified|üò®|üò∞|üò±)\b",
                    ],
                    "surprised": [
                        r"\b(surprised|shocked|amazed|wow|omg|incredible|unbelievable|üò≤|üòØ|üòÆ)\b",
                    ],
                    "disgusted": [
                        r"\b(disgusted|gross|sick|ew|yuck|nasty|ü§Æ|ü§¢)\b",
                    ],
                    "neutral": [
                        r"\b(okay|ok|fine|normal|usual|regular)\b",
                    ],
                }

            def analyze(self, text: str) -> Dict[str, float]:
                scores = {}

                for emotion, patterns in self.emotion_patterns.items():
                    score = 0.0
                    for pattern in patterns:
                        matches = len(re.findall(pattern, text, re.IGNORECASE))
                        score += matches * 0.3

                    scores[emotion] = score

                # Score par d√©faut si aucune √©motion d√©tect√©e
                if sum(scores.values()) == 0:
                    scores["neutral"] = 1.0

                return scores

        return EmotionDetector()

    def _speak_with_emotion(
        self, text: str, emotion: str = "neutral", voice_settings: Optional[Dict] = None
    ) -> bool:
        """
        Synth√©tise la parole avec √©motion en utilisant le VoiceEngine.

        Args:
            text: Texte √† synth√©tiser
            emotion: √âmotion √† appliquer ("happy", "sad", "neutral", etc.)
            voice_settings: Param√®tres vocaux optionnels

        Returns:
            True si la synth√®se a r√©ussi, False sinon

        Example:
            >>> success = orchestrator._speak_with_emotion("Hello!", "happy")
            >>> assert success == True
        """
        if not text or not text.strip():
            logger.warning("Empty text provided for speech synthesis")
            return False

        if not self.is_component_loaded("voice_engine"):
            logger.warning("Voice engine not available for speech synthesis")
            return False

        try:
            voice_engine = getattr(self, "_voice_engine")

            # Pr√©parer les param√®tres selon l'√©motion
            settings = voice_settings or {}

            # Mapping √©motions -> param√®tres vocaux
            emotion_mappings = {
                "happy": {"stability": 0.3, "similarity_boost": 0.8, "style": 1.2},
                "sad": {"stability": 0.8, "similarity_boost": 0.5, "style": 0.3},
                "excited": {"stability": 0.2, "similarity_boost": 0.9, "style": 1.5},
                "angry": {"stability": 0.9, "similarity_boost": 0.7, "style": 1.1},
                "fearful": {"stability": 0.7, "similarity_boost": 0.4, "style": 0.5},
                "neutral": {"stability": 0.5, "similarity_boost": 0.75, "style": 1.0},
            }

            emotion_settings = emotion_mappings.get(
                emotion, emotion_mappings["neutral"]
            )
            settings.update(emotion_settings)

            # V√©rifier si le voice engine a la m√©thode speak_with_emotion
            if hasattr(voice_engine, "speak_with_emotion"):
                response = voice_engine.speak_with_emotion(
                    text=text, emotion=emotion, **settings
                )
            elif hasattr(voice_engine, "generate_speech"):
                response = voice_engine.generate_speech(
                    text=text, voice_settings=settings
                )
            else:
                logger.error("Voice engine doesn't have speech generation methods")
                return False

            # V√©rifier le r√©sultat
            if response and hasattr(response, "audio_data") and response.audio_data:
                logger.info(
                    f"üéôÔ∏è Speech synthesized with emotion '{emotion}': {len(response.audio_data)} bytes"
                )
                return True
            elif response is True:  # Some implementations return just True
                logger.info(f"üéôÔ∏è Speech synthesized with emotion '{emotion}'")
                return True
            else:
                logger.warning(f"Speech synthesis returned no audio data")
                return False

        except Exception as e:
            logger.error(f"Speech synthesis failed: {e}")
            return False

    def _store_conversation(
        self,
        user_id: str,
        user_input: str,
        assistant_response: str,
        metadata: Optional[Dict] = None,
    ) -> bool:
        """
        Stocke une conversation en m√©moire persistante avec compression et indexation.

        Args:
            user_id: Identifiant utilisateur
            user_input: Message de l'utilisateur
            assistant_response: R√©ponse de l'assistant
            metadata: M√©tadonn√©es additionnelles

        Returns:
            True si le stockage a r√©ussi, False sinon

        Example:
            >>> success = orchestrator._store_conversation(
            ...     "user123",
            ...     "Hello",
            ...     "Hi there!",
            ...     {"emotion": "happy"}
            ... )
            >>> assert success == True
        """
        if not user_id:
            logger.error("User ID is required for conversation storage")
            return False

        if not self.is_component_loaded("memory_manager"):
            logger.warning("Memory manager not available for conversation storage")
            return False

        try:
            memory_manager = getattr(self, "_memory_manager")

            # Pr√©parer les donn√©es de conversation
            conversation_data = {
                "user_id": user_id,
                "user_input": user_input,
                "assistant_response": assistant_response,
                "metadata": metadata or {},
                "timestamp": datetime.now().isoformat(),
                "version": "2.0",
                "conversation_id": f"{user_id}_{int(time.time())}",
            }

            # Ajouter des m√©triques de la conversation
            conversation_data["metrics"] = {
                "user_input_length": len(user_input),
                "response_length": len(assistant_response),
                "processing_timestamp": datetime.now().timestamp(),
            }

            # Compression si la conversation est longue
            total_length = len(user_input) + len(assistant_response)
            if total_length > 1000 and hasattr(memory_manager, "compress"):
                conversation_data = memory_manager.compress(conversation_data)
                conversation_data["compressed"] = True

            # Stockage avec TTL
            storage_key = f"conversation_{user_id}_{int(time.time())}"
            ttl = 86400 * 30  # 30 jours

            # Utiliser la m√©thode appropri√©e selon l'interface du memory manager
            if hasattr(memory_manager, "store"):
                success = memory_manager.store(
                    key=storage_key, data=conversation_data, ttl=ttl
                )
            elif hasattr(memory_manager, "add_to_context"):
                memory_manager.add_to_context(
                    message=user_input, user_id=user_id, response=assistant_response
                )
                success = True
            else:
                logger.error("Memory manager has no compatible storage method")
                return False

            if success:
                logger.info(
                    f"üíæ Conversation stored for user {user_id} (key: {storage_key})"
                )
            else:
                logger.warning(f"Failed to store conversation for user {user_id}")

            return bool(success)

        except Exception as e:
            logger.error(f"Failed to store conversation: {e}")
            return False

    # ========================================================================
    # M√âTHODE CONTEXT BUILDER (M√©thode principale critique)
    # ========================================================================

    def _build_conversation_context(
        self,
        conversation_history: List[Union[Message, Dict, Any]],
        intent: str = "chat",
        user_id: Optional[str] = None,
        max_tokens: Optional[int] = None,
    ) -> ConversationContext:
        """
        Construit un contexte de conversation optimis√© et s√©curis√©.

        IMPORTANT : Accepte Messages, dicts ou autres formats pour compatibilit√©.
        Tout est normalis√© en Message avant traitement.
        """
        start_time = time.time()

        # Incr√©menter le compteur d'appels
        self._performance_metrics["calls"] += 1

        try:
            # Validation de base
            if not conversation_history:
                raise ValueError("Conversation history cannot be empty")

            # ===== NORMALISATION STRICTE =====
            # TOUT doit devenir un Message object avant de continuer
            normalized_messages = []

            for i, msg in enumerate(conversation_history):
                try:
                    # Cas 1 : C'est d√©j√† un Message
                    if isinstance(msg, Message):
                        # S'assurer que l'attribut sanitized existe
                        if not hasattr(msg, "sanitized"):
                            msg.sanitized = False
                        normalized_messages.append(msg)
                        continue

                    # Cas 2 : C'est un dict
                    elif isinstance(msg, dict):
                        # Validation minimale : il faut au moins un content
                        content = msg.get("content", "").strip()
                        if not content:
                            logger.warning(
                                f"Skipping dict at index {i} with empty content: {msg}"
                            )
                            continue

                        # Cr√©er le Message avec toutes les valeurs par d√©faut
                        new_msg = Message(
                            role=msg.get("role", "user"),
                            content=content,
                            timestamp=msg.get("timestamp", datetime.now()),
                            metadata=msg.get("metadata", {}),
                            importance_score=float(msg.get("importance_score", 1.0)),
                            is_key_message=bool(msg.get("is_key_message", False)),
                        )
                        # Marquer comme non sanitiz√©
                        new_msg.sanitized = False
                        new_msg.original_content = content  # Sauvegarder l'original
                        normalized_messages.append(new_msg)

                    # Cas 3 : C'est une string
                    elif isinstance(msg, str):
                        content = msg.strip()
                        if not content:
                            logger.warning(f"Skipping empty string at index {i}")
                            continue

                        logger.info(f"Converting string to Message: {content[:50]}...")
                        new_msg = Message(
                            role="user",
                            content=content,
                            timestamp=datetime.now(),
                            metadata={"converted_from": "string"},
                            importance_score=1.0,
                            is_key_message=False,
                        )
                        new_msg.sanitized = False
                        new_msg.original_content = content
                        normalized_messages.append(new_msg)

                    # Cas 4 : Type invalide
                    else:
                        logger.warning(
                            f"Skipping invalid message type at index {i}: {type(msg)} - {msg}"
                        )
                        continue

                except Exception as e:
                    logger.error(f"Failed to normalize message at index {i}: {e}")
                    logger.debug(f"Problematic message: {msg}")
                    continue

            # V√©rification finale
            if not normalized_messages:
                raise ValueError(
                    "No valid messages after normalization. Check input format."
                )

            logger.info(
                f"Normalized {len(normalized_messages)}/{len(conversation_history)} messages"
            )

            # ===== FIN NORMALISATION =====
            # √Ä partir d'ici, on travaille UNIQUEMENT avec normalized_messages (List[Message])

            # Validation de l'intent
            try:
                intent_enum = Intent(intent)
            except ValueError:
                logger.warning(f"Unknown intent '{intent}', defaulting to CHAT")
                intent_enum = Intent.CHAT

            # R√©cup√©ration de la strat√©gie
            strategy = self.strategy_manager.get_strategy(intent_enum)
            if max_tokens:
                strategy["max_tokens"] = max_tokens
            logger.debug(f"Using strategy for intent {intent_enum.value}: {strategy}")

            # 1. Pr√©servation du message original
            original_message = normalized_messages[-1] if normalized_messages else None

            # 2. Filtrage du bruit
            filtered_messages = []
            noise_count = 0

            for msg in normalized_messages:  # PAS conversation_history !
                if self.sanitizer.is_noise(msg.content):
                    noise_count += 1
                    logger.debug(f"Filtered noise message: {msg.content[:30]}...")
                    continue
                filtered_messages.append(msg)

            logger.info(
                f"Filtered {noise_count} noise messages from {len(normalized_messages)}"
            )

            # ===== PHASE 4: ANALYSE D'IMPORTANCE =====
            for msg in filtered_messages:
                # Calcul de l'importance
                msg.importance_score = self.importance_analyzer.calculate_importance(
                    msg.content, intent_enum.value
                )

                # Marquer comme message cl√© si tr√®s important
                if msg.importance_score >= 1.5:
                    msg.is_key_message = True

            # ===== PHASE 5: APPLICATION DE LA FEN√äTRE GLISSANTE =====
            window_size = min(strategy["window_size"], len(filtered_messages))

            # Messages cl√©s √† pr√©server absolument
            key_messages = [msg for msg in filtered_messages if msg.is_key_message]

            # Messages r√©cents avec pond√©ration
            recent_messages = (
                filtered_messages[-window_size:] if window_size > 0 else []
            )

            # S√©lection intelligente des messages
            context_messages = []

            # 1. Toujours inclure le message original
            if original_message and original_message not in context_messages:
                context_messages.append(original_message)

            # 2. Ajouter les messages cl√©s
            for key_msg in key_messages:
                if (
                    key_msg not in context_messages
                    and len(context_messages) < window_size
                ):
                    context_messages.append(key_msg)

            # 3. Compl√©ter avec les messages r√©cents qui passent le filtre de strat√©gie
            for msg in recent_messages:
                if (
                    msg not in context_messages
                    and len(context_messages) < window_size
                    and self.strategy_manager.should_include_message(msg, strategy)
                ):

                    # Pond√©ration par r√©cence
                    position_ratio = recent_messages.index(msg) / max(
                        len(recent_messages), 1
                    )
                    recency_weight = strategy["weight_recent"] ** position_ratio
                    msg.importance_score *= recency_weight

                    context_messages.append(msg)

            # ===== PHASE 6: SANITIZATION S√âCURIS√âE =====
            total_sanitization_report = {}
            sanitized_messages = []

            for msg in context_messages:
                # Pr√©server le contenu original si pas encore fait
                if not msg.sanitized:
                    msg.original_content = msg.content

                # Sanitization
                sanitized_content, report = self.sanitizer.sanitize(msg.content)

                # Cr√©er une copie du message avec le contenu sanitiz√©
                sanitized_msg = Message(
                    role=msg.role,
                    content=sanitized_content,
                    timestamp=msg.timestamp,
                    metadata=msg.metadata.copy(),
                    importance_score=msg.importance_score,
                    is_key_message=msg.is_key_message,
                    sanitized=True,
                    original_content=msg.original_content,
                )
                sanitized_messages.append(sanitized_msg)

                # Agr√©ger le rapport de sanitization
                for key, count in report.items():
                    total_sanitization_report[key] = (
                        total_sanitization_report.get(key, 0) + count
                    )

            # ===== PHASE 7: OPTIMISATION POUR LES TOKENS =====
            if strategy.get("max_tokens"):
                sanitized_messages = self.strategy_manager.optimize_for_tokens(
                    sanitized_messages, strategy
                )

            # ===== PHASE 8: TRI CHRONOLOGIQUE =====
            sanitized_messages.sort(key=lambda m: m.timestamp)

            # ===== PHASE 9: M√âTRIQUES ET STATS =====
            processing_time_ms = (time.time() - start_time) * 1000

            processing_stats = {
                "processing_time_ms": processing_time_ms,
                "original_count": len(conversation_history),
                "filtered_count": len(filtered_messages),
                "final_count": len(sanitized_messages),
                "noise_filtered": noise_count,
                "key_messages_count": len(
                    [m for m in sanitized_messages if m.is_key_message]
                ),
                "avg_importance": sum(m.importance_score for m in sanitized_messages)
                / max(len(sanitized_messages), 1),
                "strategy_applied": intent_enum.value,
                "window_size_used": len(sanitized_messages),
            }

            # ===== PHASE 10: CONSTRUCTION DU CONTEXTE FINAL =====
            context = ConversationContext(
                messages=sanitized_messages,
                intent=intent_enum,
                window_size=window_size,
                original_message=(
                    original_message if original_message in sanitized_messages else None
                ),
                key_messages=[m for m in sanitized_messages if m.is_key_message],
                metadata={
                    "user_id": user_id,
                    "strategy_used": intent_enum.value,
                    "cache_key": (
                        self._generate_cache_key(sanitized_messages, intent, user_id)
                        if hasattr(self, "_generate_cache_key")
                        else None
                    ),
                },
                sanitization_report=total_sanitization_report,
                processing_stats=processing_stats,
            )

            # ===== PHASE 11: VALIDATION FINALE =====
            # V√©rification du token count
            if context.token_count > strategy.get("max_tokens", 4000):
                logger.warning(
                    f"Context token count ({context.token_count}) exceeds recommended limit "
                    f"({strategy.get('max_tokens', 4000)})"
                )

            # ===== PHASE 12: LOGGING ET M√âTRIQUES =====
            # Tracker les m√©triques de performance
            self._performance_metrics["total_response_time"] += processing_time_ms
            self._performance_metrics["avg_response_time"] = (
                self._performance_metrics["total_response_time"]
                / self._performance_metrics["calls"]
            )

            logger.info(
                "‚úÖ Context built successfully",
                extra={
                    **context.get_summary(),
                    "user_id": user_id,
                    "processing_time_ms": processing_time_ms,
                },
            )

            return context

        except ValueError as e:
            # Re-raise ValueError as-is for input validation errors
            self._performance_metrics["errors"] += 1
            logger.error(f"‚ùå Input validation failed: {e}")
            raise
        except Exception as e:
            # Incr√©menter le compteur d'erreurs
            self._performance_metrics["errors"] += 1

            logger.error(f"‚ùå Failed to build conversation context: {e}")
            raise OrchestratorError(f"Context building failed: {e}") from e

    def _generate_cache_key(
        self, conversation_history: List[Message], intent: str, user_id: str
    ) -> str:
        """G√©n√®re une cl√© de cache pour le contexte"""
        # Cr√©er un hash des messages pour la cache (prendre les 10 derniers)
        recent_messages = (
            conversation_history[-10:]
            if len(conversation_history) > 10
            else conversation_history
        )
        content_hash = hashlib.md5(
            "".join(f"{msg.role}:{msg.content}" for msg in recent_messages).encode()
        ).hexdigest()[:8]

        return f"ctx_{user_id}_{intent}_{content_hash}"

    # ========================================================================
    # M√âTHODES UTILITAIRES ET STATUS
    # ========================================================================

    def get_status(self) -> Dict[str, Any]:
        """
        R√©cup√®re le statut complet de l'orchestrateur

        Returns:
            Dict avec toutes les informations de statut
        """
        return {
            "orchestrator": {
                "initialized": self._initialized,
                "health_status": self._health_status,
                "last_health_check": (
                    self._last_health_check.isoformat()
                    if self._last_health_check
                    else None
                ),
                "version": "2.0",
            },
            "components": self.get_all_components_status(),
            "performance_metrics": self._performance_metrics.copy(),
            "sanitizer": {
                "patterns_count": len(self.sanitizer.patterns),
                "noise_patterns_count": len(self.sanitizer.NOISE_PATTERNS),
            },
            "strategy_manager": {
                "available_intents": [intent.value for intent in Intent],
                "strategies_count": len(self.strategy_manager.STRATEGIES),
            },
        }

    def health_check(self) -> Dict[str, Any]:
        """
        Effectue un health check complet

        Returns:
            Dict avec les r√©sultats du health check
        """
        self._last_health_check = datetime.now()
        health_results = {
            "timestamp": self._last_health_check.isoformat(),
            "overall_status": "healthy",
            "components": {},
            "errors": [],
        }

        # V√©rifier chaque composant
        for comp_name, comp_info in self._components.items():
            try:
                if comp_info.instance and hasattr(comp_info.instance, "health_check"):
                    comp_health = comp_info.instance.health_check()
                    health_results["components"][comp_name] = {
                        "status": "healthy" if comp_health else "unhealthy",
                        "loaded": True,
                    }
                else:
                    health_results["components"][comp_name] = {
                        "status": "unknown",
                        "loaded": comp_info.instance is not None,
                    }
            except Exception as e:
                health_results["components"][comp_name] = {
                    "status": "error",
                    "error": str(e),
                    "loaded": False,
                }
                health_results["errors"].append(f"{comp_name}: {e}")

        # D√©terminer le statut global
        unhealthy_components = [
            name
            for name, status in health_results["components"].items()
            if status["status"] in ["unhealthy", "error"]
        ]

        if unhealthy_components:
            health_results["overall_status"] = "degraded"
            if len(unhealthy_components) >= len(self._components) / 2:
                health_results["overall_status"] = "unhealthy"

        self._health_status = health_results["overall_status"] == "healthy"

        return health_results

    def get_metrics(self) -> Dict[str, Any]:
        """R√©cup√®re les m√©triques de performance"""
        return {
            **self._performance_metrics,
            "uptime_seconds": (
                (datetime.now() - self._last_health_check).total_seconds()
                if self._last_health_check
                else 0
            ),
            "components_loaded": len(
                [
                    c
                    for c in self._components.values()
                    if c.status == ComponentStatus.LOADED
                ]
            ),
            "total_components": len(self._components),
        }


# ============================================================================
# FONCTION DE TEST POUR LE D√âVELOPPEMENT
# ============================================================================


async def test_jeffrey_orchestrator():
    """Test complet de l'orchestrateur"""
    print("üß™ TESTING JEFFREY V1 ORCHESTRATOR")
    print("=" * 50)

    # Initialize orchestrator
    jeffrey = JeffreyOrchestrator()

    # Test 1: Status check
    print("\nüìä STATUS CHECK:")
    status = jeffrey.get_status()
    print(f"   Initialized: {status['orchestrator']['initialized']}")
    print(f"   Health: {status['orchestrator']['health_status']}")
    print(
        f"   Components loaded: {len([c for c in status['components'].values() if c['loaded']])}"
    )

    # Test 2: Context building
    print("\nüß† CONTEXT BUILDING TEST:")
    test_messages = [
        Message(role="user", content="Hello Jeffrey!"),
        Message(role="assistant", content="Hi there! How can I help you?"),
        Message(role="user", content="My email is test@example.com"),
        Message(role="user", content="ok"),  # Noise
        Message(role="user", content="Can you analyze this document for me?"),
    ]

    try:
        context = jeffrey._build_conversation_context(test_messages, "chat")
        print(f"   ‚úÖ Context built successfully")
        print(f"   Messages: {len(context.messages)}")
        print(f"   Tokens: {context.token_count}")
        print(f"   Sanitized items: {context.total_sanitized}")
        print(
            f"   Processing time: {context.processing_stats['processing_time_ms']:.1f}ms"
        )
    except Exception as e:
        print(f"   ‚ùå Context building failed: {e}")

    # Test 3: Emotion detection
    print("\nüòä EMOTION DETECTION TEST:")
    emotions = jeffrey._detect_emotion_from_text("I'm so happy and excited!")
    print(f"   Emotions detected: {emotions}")

    # Test 4: Health check
    print("\nüè• HEALTH CHECK:")
    health = jeffrey.health_check()
    print(f"   Overall status: {health['overall_status']}")
    print(f"   Components checked: {len(health['components'])}")

    # Test 5: Metrics
    print("\nüìà METRICS:")
    metrics = jeffrey.get_metrics()
    print(f"   Total calls: {metrics['calls']}")
    print(f"   Errors: {metrics['errors']}")
    print(f"   Avg response time: {metrics['avg_response_time']:.1f}ms")

    print("\n‚úÖ All tests completed!")


if __name__ == "__main__":
    """Direct execution for testing"""
    try:
        asyncio.run(test_jeffrey_orchestrator())
    except KeyboardInterrupt:
        print("\nüëã Test interrupted")
    except Exception as e:
        print(f"\n‚ùå Test error: {e}")
        import traceback

        traceback.print_exc()
