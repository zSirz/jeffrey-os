#!/usr/bin/env python3
"""
Test de conversation r√©elle avec le Bridge V3 et Ollama
"""

import os
import sys
import time

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.jeffrey.interfaces.ui.jeffrey_ui_bridge import JeffreyUIBridge


def test_real_conversation():
    """Test une vraie conversation avec Ollama"""
    print("\nüó£Ô∏è TEST DE CONVERSATION R√âELLE AVEC JEFFREY")
    print("=" * 60)

    bridge = JeffreyUIBridge()
    time.sleep(2)  # Laisser le warmup se faire

    # Questions de test
    test_messages = [
        ("Bonjour Jeffrey, comment vas-tu ?", "friendly"),
        ("Quelle est la capitale de la France ?", "curious"),
        ("Raconte-moi une blague courte", "playful"),
        ("Merci Jeffrey, au revoir !", "grateful"),
    ]

    for i, (message, emotion) in enumerate(test_messages, 1):
        print(f"\n--- Message {i} ---")
        print(f"üë§ User: {message}")
        print(f"   √âmotion: {emotion}")

        result = {"done": False, "response": None, "error": None}
        start_time = time.time()

        def on_start():
            print("   ‚è≥ Jeffrey r√©fl√©chit...")

        def on_complete(text, metadata):
            result["done"] = True
            result["response"] = text
            result["metadata"] = metadata

        def on_error(error):
            result["done"] = True
            result["error"] = error

        # Envoyer le message
        bridge.send_message(
            message,
            emotion=emotion,
            priority=5,
            on_start=on_start,
            on_complete=on_complete,
            on_error=on_error,
        )

        # Attendre la r√©ponse (max 30s)
        timeout = 30
        while not result["done"] and time.time() - start_time < timeout:
            time.sleep(0.5)
            print(".", end="", flush=True)

        print()  # Nouvelle ligne

        if result["error"]:
            print(f"   ‚ùå Erreur: {result['error']}")
        elif result["response"]:
            # Afficher la r√©ponse
            response_text = result["response"][:300]  # Limiter l'affichage
            if len(result["response"]) > 300:
                response_text += "..."

            print(f"ü§ñ Jeffrey: {response_text}")

            # Afficher les m√©triques
            metadata = result.get("metadata", {})
            latency = metadata.get("latency_ms", 0)
            from_cache = metadata.get("from_cache", False)

            if from_cache:
                print(f"   ‚ö° R√©ponse du cache en {latency:.1f}ms")
            else:
                print(f"   ‚è±Ô∏è R√©ponse g√©n√©r√©e en {latency:.1f}ms")

            # V√©rifier que c'est une vraie r√©ponse (pas un stub)
            if len(result["response"]) > 50 and "Jeffrey" not in result["response"][:20]:
                print("   ‚úÖ Vraie r√©ponse g√©n√©r√©e")
            elif from_cache:
                print("   ‚úÖ R√©ponse du cache")
            else:
                print("   ‚ö†Ô∏è R√©ponse courte ou stub")
        else:
            print("   ‚ö†Ô∏è Pas de r√©ponse re√ßue")

        # Pause entre les messages
        time.sleep(1)

    # Afficher les m√©triques finales
    print("\n" + "=" * 60)
    print("üìä M√âTRIQUES FINALES")
    print("=" * 60)

    metrics = bridge.get_metrics()

    print(
        f"""
    Total requ√™tes:      {metrics['total_requests']}
    Cache hits:          {metrics['cache_hits']} ({metrics['cache_hit_rate']:.1f}%)
    Streaming:           {metrics['streaming_requests']} ({metrics['streaming_rate']:.1f}%)
    Circuit breaks:      {metrics['circuit_breaks']} ({metrics['circuit_break_rate']:.1f}%)
    Rate limits:         {metrics['rate_limits']} ({metrics['rate_limit_rate']:.1f}%)
    Latence moyenne:     {metrics['avg_latency_ms']:.1f}ms
    Queue size:          {metrics['queue_size']}
    Circuit state:       {metrics['circuit_state']}
    Connection healthy:  {metrics['connection_healthy']}
    """
    )

    # Test du cache : renvoyer le m√™me message
    print("\nüîÑ TEST DU CACHE")
    print("=" * 60)
    print("Renvoi du premier message pour tester le cache...")

    result2 = {"done": False}

    def on_complete2(text, metadata):
        result2["done"] = True
        result2["response"] = text
        result2["from_cache"] = metadata.get("from_cache", False)
        result2["latency"] = metadata.get("latency_ms", 0)

    bridge.send_message("Bonjour Jeffrey, comment vas-tu ?", emotion="friendly", on_complete=on_complete2)

    # Attendre
    for _ in range(10):
        if result2["done"]:
            break
        time.sleep(0.1)

    if result2.get("from_cache"):
        print(f"‚úÖ Cache hit! R√©ponse instantan√©e en {result2['latency']:.1f}ms")
    else:
        print(f"‚ö†Ô∏è Cache miss, nouvelle g√©n√©ration en {result2.get('latency', 0):.1f}ms")

    # Shutdown propre
    bridge.shutdown()
    print("\n‚úÖ Test termin√© avec succ√®s!")


if __name__ == "__main__":
    test_real_conversation()
