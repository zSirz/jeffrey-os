# üöÄ Jeffrey OS - Guide d'Installation

## Pr√©requis

- **Python 3.11+** (obligatoire)
- **Ollama** (recommand√© pour les capacit√©s LLM)
- **Redis** (optionnel, pour cache distribu√©)
- **macOS/Linux** (recommand√© pour uvloop)

## Installation Rapide

### 1. Cloner le repository

```bash
git clone https://github.com/votre-repo/jeffrey-os.git
cd jeffrey-os
```

### 2. Installation automatique

```bash
# Rendre le script ex√©cutable
chmod +x install_jeffrey.sh

# Lancer l'installation
./install_jeffrey.sh
```

Le script va:
- ‚úÖ V√©rifier la version Python
- ‚úÖ Cr√©er un environnement virtuel
- ‚úÖ Installer toutes les d√©pendances
- ‚úÖ Cr√©er les dossiers n√©cessaires
- ‚úÖ G√©n√©rer un fichier .env de configuration

### 3. Installation manuelle (alternative)

```bash
# Cr√©er l'environnement virtuel
python3 -m venv .venv_prod

# Activer l'environnement
source .venv_prod/bin/activate  # Linux/Mac
# ou
.venv_prod\Scripts\activate  # Windows

# Installer les d√©pendances
pip install -r requirements.txt

# Pour les d√©veloppeurs
pip install -r requirements-dev.txt
```

## Configuration

### 1. Ollama (pour LLM)

```bash
# Installer Ollama (Mac)
brew install ollama

# D√©marrer Ollama
ollama serve

# T√©l√©charger le mod√®le Mistral
ollama pull mistral:7b-instruct
```

### 2. Redis (optionnel)

```bash
# Mac
brew install redis
brew services start redis

# Linux
sudo apt install redis-server
sudo systemctl start redis
```

### 3. Variables d'environnement

√âditer le fichier `.env`:

```env
# Configuration Jeffrey
JEFFREY_ENV=production
JEFFREY_LOG_LEVEL=INFO

# Ollama
OLLAMA_HOST=http://localhost:9010
OLLAMA_MODEL=mistral:7b-instruct

# Redis (optionnel)
REDIS_HOST=localhost
REDIS_PORT=6379
```

## V√©rification de l'installation

### 1. V√©rifier les d√©pendances

```bash
python check_deps.py
```

### 2. Test basique

```bash
python tests/test_bridge_v3_basic.py
```

### 3. Test conversation

```bash
python tests/test_bridge_v3_conversation.py
```

### 4. Interface graphique

```bash
python test_kivy_integration.py
```

## Structure des d√©pendances

### Core (obligatoires)
- `httpx` - Client HTTP async
- `networkx` - Op√©rations sur graphes
- `kivy` - Interface graphique
- `msgpack` - S√©rialisation binaire
- `pydantic` - Validation de donn√©es

### Neural Architecture
- `redis` - Cache et m√©moire partag√©e
- `nats-py` - Message bus neural

### Machine Learning
- `numpy` - Calcul num√©rique
- `scikit-learn` - ML classique
- `langdetect` - D√©tection de langue

### Performance
- `uvloop` - Optimisation asyncio (Linux/Mac)
- `prometheus-client` - M√©triques

## Troubleshooting

### Python version incorrecte
```bash
# Installer Python 3.11 avec pyenv
pyenv install 3.11.6
pyenv local 3.11.6
```

### Import errors
```bash
# R√©installer toutes les d√©pendances
pip install --force-reinstall -r requirements.txt
```

### Ollama ne r√©pond pas
```bash
# V√©rifier qu'Ollama est lanc√©
curl http://localhost:9010/api/tags

# Red√©marrer Ollama
killall ollama
ollama serve
```

### Interface Kivy ne se lance pas
```bash
# Installer les d√©pendances syst√®me (Mac)
brew install sdl2 sdl2_image sdl2_ttf sdl2_mixer

# Linux
sudo apt-get install python3-kivy
```

## Support

Pour toute question ou probl√®me:
1. V√©rifier les logs dans `logs/`
2. Consulter la documentation dans `docs/`
3. Ouvrir une issue sur GitHub

## Licence

MIT License - Voir LICENSE.md
