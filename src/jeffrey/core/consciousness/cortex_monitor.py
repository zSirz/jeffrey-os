#!/usr/bin/env python3
"""
Cortex Monitor - Syst√®me de surveillance temps r√©el pour l'architecture cognitive de Jeffrey OS

Ce module impl√©mente un syst√®me de monitoring complet et professionnel pour surveiller
en temps r√©el l'√©tat de sant√©, les performances, et l'√©volution du cortex neuronal.
Il fournit des tableaux de bord dynamiques, des m√©triques d√©taill√©es, des alertes
automatiques, et des recommandations d'optimisation intelligentes.

Le moniteur suit les composants critiques incluant l'utilisation syst√®me, les performances
de m√©moire √©pisodique/s√©mantique, la sant√© des connexions Redis, les m√©triques de fairness,
les temps de r√©ponse, et l'√©volution de la conscience. Il g√©n√®re des rapports exportables
et maintient un historique des m√©triques pour l'analyse de tendances.

Fonctionnalit√©s principales:
- Surveillance temps r√©el multi-composants
- Alertes automatiques bas√©es sur seuils configurables
- Tableaux de bord interactifs avec actualisation continue
- Export de m√©triques au format JSON pour analyse externe
- Recommandations d'optimisation contextuelles
- Monitoring de l'√©volution cognitive et des insights de r√™ve

Utilisation:
    monitor = CortexMonitor(cortex_instance)
    monitor.display_live_dashboard()  # Interface temps r√©el
    status = monitor.get_comprehensive_status()  # Rapport complet
"""

from __future__ import annotations

import json
import os
import sys
import threading
import time
from collections import Counter, deque
from datetime import datetime
from pathlib import Path
from typing import Any

try:
    import psutil

    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    print("‚ö†Ô∏è psutil non disponible - m√©triques syst√®me limit√©es")

try:
    import redis

    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    print("‚ö†Ô∏è Redis non disponible - pas de monitoring Redis")

# Import du syst√®me
sys.path.append(str(Path(__file__).parent.parent))
from memory_bridge import get_memory_bridge


class CortexMonitor:
    """
    Syst√®me de monitoring professionnel pour surveillance cognitive temps r√©el.

    Orchestre la surveillance compl√®te du cortex neuronal avec collecte de m√©triques
    multi-dimensionnelles, d√©tection d'anomalies, g√©n√©ration d'alertes intelligentes,
    et visualisation dynamique des performances. Maintient l'historique des donn√©es
    pour analyse de tendances et optimisation pr√©dictive.
    """

    def __init__(self, cortex: Any | None = None) -> None:
        """
        Initialise le syst√®me de monitoring avec configuration des seuils et m√©triques.

        Args:
            cortex: Instance du cortex √† surveiller (r√©cup√©r√©e automatiquement si None)
        """
        self.cortex = cortex or get_memory_bridge().cortex
        self.bridge = get_memory_bridge()

        # M√©triques temps r√©el
        self.start_time = datetime.now()
        self.metrics_history = deque(maxlen=100)  # 100 derni√®res mesures
        self.performance_alerts = []
        self.health_alerts = []

        # Configuration monitoring
        self.refresh_interval = 5  # secondes
        self.alert_thresholds = {
            'memory_usage_mb': 1000,
            'cpu_percent': 80,
            'response_time_ms': 2000,
            'error_rate': 0.1,
            'fairness_score_min': 0.7,
        }

        # √âtat du monitoring
        self.monitoring_active = False
        self.monitor_thread = None

        print("üìä CortexMonitor initialis√©")

    def get_comprehensive_status(self) -> dict[str, Any]:
        """
        G√©n√®re un rapport d'√©tat complet et structur√© du syst√®me cognitif.

        Collecte et agr√®ge toutes les m√©triques disponibles incluant syst√®me,
        cortex, m√©moire, performance, sant√©, √©volution, alertes actives,
        et recommandations d'optimisation contextuelles.

        Returns:
            Dict[str, Any]: Rapport complet avec timestamp, uptime, m√©triques
                           multi-dimensionnelles, alertes, et recommandations
        """

        status = {
            "timestamp": datetime.now().isoformat(),
            "uptime": str(datetime.now() - self.start_time),
            "system": self._get_system_metrics(),
            "cortex": self._get_cortex_metrics(),
            "memory": self._get_memory_metrics(),
            "performance": self._get_performance_metrics(),
            "health": self._get_health_metrics(),
            "evolution": self._get_evolution_metrics(),
            "alerts": self._get_current_alerts(),
            "recommendations": self._generate_recommendations(),
        }

        return status

    def _get_system_metrics(self) -> dict[str, Any]:
        """
        Collecte les m√©triques syst√®me fondamentales via psutil.

        R√©cup√®re l'utilisation CPU, consommation m√©moire processus et syst√®me,
        nombre de threads, fichiers ouverts, espace disque disponible.

        Returns:
            Dict[str, Any]: M√©triques syst√®me avec platform, versions, utilisation
                           ressources, ou messages d'erreur si psutil indisponible
        """

        metrics = {"platform": sys.platform, "python_version": sys.version.split()[0]}

        if PSUTIL_AVAILABLE:
            try:
                process = psutil.Process(os.getpid())

                metrics.update(
                    {
                        "cpu_percent": psutil.cpu_percent(interval=0.1),
                        "memory_usage_mb": process.memory_info().rss / 1024 / 1024,
                        "memory_percent": process.memory_percent(),
                        "thread_count": process.num_threads(),
                        "open_files": len(process.open_files()),
                        "system_memory_total_gb": psutil.virtual_memory().total / 1024**3,
                        "system_memory_available_gb": psutil.virtual_memory().available / 1024**3,
                        "disk_usage_percent": psutil.disk_usage('/').percent
                        if os.name != 'nt'
                        else psutil.disk_usage('C:\\').percent,
                    }
                )
            except Exception as e:
                metrics["error"] = f"Erreur psutil: {e}"
        else:
            metrics["warning"] = "psutil non disponible"

        return metrics

    def _get_cortex_metrics(self) -> dict[str, Any]:
        """
        Extraction des m√©triques sp√©cifiques √† l'architecture cognitive du cortex.

        Analyse l'√©tat du bridge m√©moire, niveaux de conscience, compteurs de m√©moire
        √©pisodique/s√©mantique/relationnelle, performances de recherche/stockage,
        et scores de fairness moyens.

        Returns:
            Dict[str, Any]: M√©triques cognitives incluant sant√© bridge, interactions,
                           erreurs, contenus m√©moriels, et performances op√©rationnelles
        """

        metrics = {
            "bridge_healthy": self.bridge.is_healthy,
            "fallback_mode": self.bridge.fallback_mode,
            "total_interactions": self.bridge.total_interactions,
            "error_count": self.bridge.error_count,
            "error_rate": self.bridge.error_count / max(1, self.bridge.total_interactions),
        }

        # M√©triques du cortex lui-m√™me
        if hasattr(self.cortex, 'cortex'):
            cortex_core = self.cortex.cortex

            if hasattr(cortex_core, 'consciousness_level'):
                metrics["consciousness_level"] = cortex_core.consciousness_level

            if hasattr(cortex_core, 'episodic_memory'):
                metrics["episodic_memory_count"] = len(cortex_core.episodic_memory)

            if hasattr(cortex_core, 'semantic_memory'):
                metrics["semantic_memory_count"] = len(cortex_core.semantic_memory)

            if hasattr(cortex_core, 'relational_memory'):
                metrics["relational_memory_count"] = len(cortex_core.relational_memory)

            if hasattr(cortex_core, 'performance_metrics'):
                perf = cortex_core.performance_metrics
                if perf.get('search_times'):
                    metrics["avg_search_time_ms"] = sum(perf['search_times']) / len(perf['search_times']) * 1000
                if perf.get('storage_times'):
                    metrics["avg_storage_time_ms"] = sum(perf['storage_times']) / len(perf['storage_times']) * 1000
                if perf.get('fairness_scores'):
                    metrics["avg_fairness_score"] = sum(perf['fairness_scores']) / len(perf['fairness_scores'])

        return metrics

    def _get_memory_metrics(self) -> dict[str, Any]:
        """
        Analyse approfondie des syst√®mes de m√©moire √©pisodique et distributions.

        Examine la m√©moire √©pisodique pour extraire statistiques temporelles,
        distributions √©motionnelles des souvenirs r√©cents, niveaux de sensibilit√©,
        et scores de fairness des interactions pass√©es.

        Returns:
            Dict[str, Any]: M√©triques m√©morielles avec compteurs temporels,
                           distributions √©motionnelles/sensibilit√©, fairness r√©cente
        """

        metrics = {}

        if hasattr(self.cortex, 'cortex') and hasattr(self.cortex.cortex, 'episodic_memory'):
            episodic = self.cortex.cortex.episodic_memory

            # Statistiques temporelles
            if episodic:
                now = datetime.now()
                recent_count = sum(1 for m in episodic if (now - getattr(m, 'timestamp', now)).total_seconds() < 3600)

                metrics.update(
                    {
                        "recent_memories_1h": recent_count,
                        "oldest_memory": min(getattr(m, 'timestamp', now) for m in episodic).isoformat()
                        if episodic
                        else None,
                        "newest_memory": max(getattr(m, 'timestamp', now) for m in episodic).isoformat()
                        if episodic
                        else None,
                    }
                )

                # Distribution √©motionnelle
                emotions = [getattr(m, 'emotion', 'unknown') for m in episodic[-20:]]  # 20 derniers
                emotion_dist = dict(Counter(emotions))
                metrics["emotion_distribution"] = emotion_dist

                # Niveaux de sensibilit√©
                sensitivity_levels = [getattr(m, 'sensitivity_level', 'normal') for m in episodic[-20:]]
                sensitivity_dist = dict(Counter(sensitivity_levels))
                metrics["sensitivity_distribution"] = sensitivity_dist

                # Scores de fairness r√©cents
                fairness_scores = [getattr(m, 'fairness_score', 1.0) for m in episodic[-10:]]
                if fairness_scores:
                    metrics["recent_fairness_avg"] = sum(fairness_scores) / len(fairness_scores)
                    metrics["recent_fairness_min"] = min(fairness_scores)

        return metrics

    def _get_performance_metrics(self) -> dict[str, Any]:
        """
        Collecte et analyse des m√©triques de performance op√©rationnelles d√©taill√©es.

        Calcule statistiques de temps de r√©ponse pour recherche/stockage,
        m√©triques de fairness avec d√©tection de violations, throughput
        op√©rationnel, et ratios performance/temps.

        Returns:
            Dict[str, Any]: M√©triques performance avec temps moyens/min/max,
                           violations fairness, compteurs op√©rationnels, throughput
        """

        metrics = {}

        if hasattr(self.cortex, 'cortex') and hasattr(self.cortex.cortex, 'performance_metrics'):
            perf = self.cortex.cortex.performance_metrics

            # Temps de r√©ponse
            if perf.get('search_times'):
                search_times = list(perf['search_times'])
                metrics.update(
                    {
                        "search_time_avg_ms": sum(search_times) / len(search_times) * 1000,
                        "search_time_max_ms": max(search_times) * 1000,
                        "search_time_min_ms": min(search_times) * 1000,
                        "search_operations_count": len(search_times),
                    }
                )

            if perf.get('storage_times'):
                storage_times = list(perf['storage_times'])
                metrics.update(
                    {
                        "storage_time_avg_ms": sum(storage_times) / len(storage_times) * 1000,
                        "storage_time_max_ms": max(storage_times) * 1000,
                        "storage_operations_count": len(storage_times),
                    }
                )

            # M√©triques de fairness
            if perf.get('fairness_scores'):
                fairness_scores = list(perf['fairness_scores'])
                metrics.update(
                    {
                        "fairness_score_avg": sum(fairness_scores) / len(fairness_scores),
                        "fairness_score_min": min(fairness_scores),
                        "fairness_checks_count": len(fairness_scores),
                        "fairness_violations": sum(1 for score in fairness_scores if score < 0.8),
                    }
                )

            # Throughput
            metrics["total_memory_operations"] = perf.get('total_memories', 0)

            uptime_hours = (datetime.now() - self.start_time).total_seconds() / 3600
            if uptime_hours > 0:
                metrics["operations_per_hour"] = perf.get('total_memories', 0) / uptime_hours

        return metrics

    def _get_health_metrics(self) -> dict[str, Any]:
        """
        √âvaluation compl√®te de la sant√© des composants syst√®me critiques.

        V√©rifie l'√©tat du bridge m√©moire, cortex, connexions Redis,
        syst√®me de fichiers, et d√©termine l'√©tat de sant√© global
        bas√© sur l'agr√©gation des composants individuels.

        Returns:
            Dict[str, Any]: √âtat sant√© global et d√©tails par composant
                           (healthy/degraded/unhealthy/error)
        """

        health = {"overall_status": "unknown", "components": {}}

        # Sant√© du bridge
        bridge_health = self.bridge.health_check()
        health["components"]["memory_bridge"] = "healthy" if bridge_health else "unhealthy"

        # Sant√© du cortex
        if hasattr(self.cortex, 'cortex') and hasattr(self.cortex.cortex, 'health_check'):
            try:
                cortex_health = self.cortex.cortex.health_check()
                if isinstance(cortex_health, dict):
                    health["components"]["cortex"] = cortex_health.get('overall_health', 'unknown')
                    health["cortex_details"] = cortex_health.get('components', {})
                else:
                    health["components"]["cortex"] = "healthy" if cortex_health else "unhealthy"
            except Exception as e:
                health["components"]["cortex"] = f"error: {e}"
        else:
            health["components"]["cortex"] = "no_health_check"

        # Sant√© Redis
        health["components"]["redis"] = self._check_redis_health()

        # Sant√© du syst√®me de fichiers
        health["components"]["filesystem"] = self._check_filesystem_health()

        # D√©terminer l'√©tat global
        component_states = list(health["components"].values())
        if any("error" in state or state == "unhealthy" for state in component_states):
            health["overall_status"] = "unhealthy"
        elif any(state in ["degraded", "warning"] for state in component_states):
            health["overall_status"] = "degraded"
        elif all(state == "healthy" for state in component_states):
            health["overall_status"] = "healthy"
        else:
            health["overall_status"] = "partial"

        return health

    def _get_evolution_metrics(self) -> dict[str, Any]:
        """
        Analyse des m√©triques d'√©volution cognitive et d'apprentissage adaptatif.

        Trace l'√©volution du niveau de conscience, entit√©s reconnues,
        relations √©tablies, insights g√©n√©r√©s par le syst√®me de r√™ve,
        et taux de croissance cognitive.

        Returns:
            Dict[str, Any]: M√©triques √©volutives avec conscience actuelle/delta,
                           entit√©s/relations, cycles de r√™ve, insights second-ordre
        """

        evolution = {}

        if hasattr(self.cortex, 'cortex'):
            cortex_core = self.cortex.cortex

            # √âvolution de conscience
            if hasattr(cortex_core, 'consciousness_level') and hasattr(cortex_core, 'consciousness_trajectory'):
                evolution["current_consciousness"] = cortex_core.consciousness_level

                trajectory = cortex_core.consciousness_trajectory
                if len(trajectory) >= 2:
                    first_level = trajectory[0].get('level', 0)
                    last_level = trajectory[-1].get('level', 0)
                    evolution["consciousness_delta"] = last_level - first_level
                    evolution["consciousness_growth_rate"] = evolution["consciousness_delta"] / len(trajectory)

            # Entit√©s reconnues
            if hasattr(cortex_core, 'relational_memory'):
                evolution["recognized_entities"] = list(cortex_core.relational_memory.keys())
                evolution["relationship_count"] = len(cortex_core.relational_memory)

            # Insights de r√™ve
            if hasattr(self.cortex, 'dream_engine'):
                dream_engine = self.cortex.dream_engine
                if hasattr(dream_engine, 'insights_second_order'):
                    evolution["total_insights"] = len(dream_engine.insights_second_order)
                if hasattr(dream_engine, 'dream_cycles'):
                    evolution["dream_cycles"] = dream_engine.dream_cycles

        return evolution

    def _check_redis_health(self) -> str:
        """
        Diagnostic de connectivit√© et r√©activit√© du serveur Redis.

        Teste la connexion, latence ping, et d√©tecte les timeouts
        pour √©valuer la sant√© de l'infrastructure de communication.

        Returns:
            str: √âtat Redis ('healthy', 'disconnected', 'timeout', 'unavailable', 'error')
        """
        if not REDIS_AVAILABLE:
            return "unavailable"

        try:
            r = redis.Redis(host='localhost', port=6380, decode_responses=True, socket_timeout=1)
            r.ping()
            return "healthy"
        except redis.ConnectionError:
            return "disconnected"
        except redis.TimeoutError:
            return "timeout"
        except Exception as e:
            return f"error: {str(e)[:50]}"

    def _check_filesystem_health(self) -> str:
        """
        Diagnostic de l'int√©grit√© et disponibilit√© du syst√®me de fichiers.

        V√©rifie l'espace disque disponible, permissions d'√©criture,
        et acc√®s aux r√©pertoires critiques pour la persistance.

        Returns:
            str: √âtat filesystem ('healthy', 'low_space', 'critical_space',
                 'permission_error', 'error')
        """
        try:
            # V√©rifier l'espace disque
            if PSUTIL_AVAILABLE:
                disk_usage = psutil.disk_usage('/' if os.name != 'nt' else 'C:\\')
                if disk_usage.percent > 95:
                    return "critical_space"
                elif disk_usage.percent > 85:
                    return "low_space"

            # V√©rifier l'acc√®s en √©criture
            test_file = Path("core/memory/.health_check")
            test_file.touch()
            test_file.unlink()

            return "healthy"

        except PermissionError:
            return "permission_error"
        except OSError as e:
            return f"error: {str(e)[:50]}"

    def _get_current_alerts(self) -> list[dict[str, Any]]:
        """
        G√©n√©ration d'alertes bas√©es sur l'√©valuation des seuils configur√©s.

        Compare les m√©triques courantes aux seuils d'alerte pour d√©tecter
        usage m√©moire/CPU excessif, taux d'erreur √©lev√©, performances
        d√©grad√©es, et violations de fairness.

        Returns:
            List[Dict[str, Any]]: Liste d'alertes avec type, s√©v√©rit√©,
                                 message descriptif, et timestamp
        """

        alerts = []

        # R√©cup√©rer les m√©triques syst√®me
        system_metrics = self._get_system_metrics()
        cortex_metrics = self._get_cortex_metrics()
        performance_metrics = self._get_performance_metrics()

        # V√©rifier les seuils d'alerte
        if system_metrics.get('memory_usage_mb', 0) > self.alert_thresholds['memory_usage_mb']:
            alerts.append(
                {
                    "type": "memory_usage",
                    "severity": "warning",
                    "message": f"Utilisation m√©moire √©lev√©e: {system_metrics['memory_usage_mb']:.1f}MB",
                    "timestamp": datetime.now().isoformat(),
                }
            )

        if system_metrics.get('cpu_percent', 0) > self.alert_thresholds['cpu_percent']:
            alerts.append(
                {
                    "type": "cpu_usage",
                    "severity": "warning",
                    "message": f"Utilisation CPU √©lev√©e: {system_metrics['cpu_percent']:.1f}%",
                    "timestamp": datetime.now().isoformat(),
                }
            )

        if cortex_metrics.get('error_rate', 0) > self.alert_thresholds['error_rate']:
            alerts.append(
                {
                    "type": "error_rate",
                    "severity": "critical",
                    "message": f"Taux d'erreur √©lev√©: {cortex_metrics['error_rate']:.2%}",
                    "timestamp": datetime.now().isoformat(),
                }
            )

        if performance_metrics.get('search_time_avg_ms', 0) > self.alert_thresholds['response_time_ms']:
            alerts.append(
                {
                    "type": "performance",
                    "severity": "warning",
                    "message": f"Temps de recherche √©lev√©: {performance_metrics['search_time_avg_ms']:.1f}ms",
                    "timestamp": datetime.now().isoformat(),
                }
            )

        if performance_metrics.get('fairness_score_avg', 1.0) < self.alert_thresholds['fairness_score_min']:
            alerts.append(
                {
                    "type": "fairness",
                    "severity": "critical",
                    "message": f"Score de fairness bas: {performance_metrics['fairness_score_avg']:.3f}",
                    "timestamp": datetime.now().isoformat(),
                }
            )

        return alerts

    def _generate_recommendations(self) -> list[str]:
        """
        Analyse intelligente pour g√©n√©rer recommandations d'optimisation contextuelles.

        Examine les m√©triques de performance, sant√©, et utilisation
        pour sugg√©rer actions correctives sp√©cifiques et am√©liorations
        d'efficacit√© du syst√®me cognitif.

        Returns:
            List[str]: Recommandations prioritaires pour optimisation
                      m√©moire, performance, s√©curit√©, infrastructure
        """

        recommendations = []

        # Analyser les m√©triques
        system_metrics = self._get_system_metrics()
        cortex_metrics = self._get_cortex_metrics()
        performance_metrics = self._get_performance_metrics()
        health_metrics = self._get_health_metrics()

        # Recommandations m√©moire
        if system_metrics.get('memory_usage_mb', 0) > 500:
            recommendations.append("Consid√©rer l'optimisation de l'utilisation m√©moire")

        if cortex_metrics.get('episodic_memory_count', 0) > 50000:
            recommendations.append("Envisager la compression des anciens souvenirs")

        # Recommandations performance
        if performance_metrics.get('search_time_avg_ms', 0) > 1000:
            recommendations.append("Optimiser l'index FAISS ou activer la mise en cache")

        # Recommandations s√©curit√©
        if performance_metrics.get('fairness_violations', 0) > 0:
            recommendations.append("R√©viser les r√©ponses pour am√©liorer la fairness")

        # Recommandations infrastructure
        if health_metrics["components"].get("redis") != "healthy":
            recommendations.append("V√©rifier la configuration Redis")

        if cortex_metrics.get('error_rate', 0) > 0.05:
            recommendations.append("Analyser les logs d'erreur pour identifier les causes")

        return recommendations

    def display_live_dashboard(self) -> None:
        """
        Interface de monitoring temps r√©el avec actualisation continue.

        Affiche tableau de bord dynamique avec m√©triques syst√®me,
        √©tat cortex, performance m√©moire, √©volution cognitive,
        sant√© composants, alertes actives, et recommandations.
        Actualisation automatique configurable.

        Raises:
            KeyboardInterrupt: Arr√™t gracieux via Ctrl+C
        """

        try:
            while True:
                # Nettoyer l'√©cran
                os.system('clear' if os.name == 'posix' else 'cls')

                # R√©cup√©rer le statut complet
                status = self.get_comprehensive_status()

                # En-t√™te
                print("üß† JEFFREY CORTEX MONITOR - TABLEAU DE BORD TEMPS R√âEL")
                print("=" * 80)
                print(f"‚è∞ {status['timestamp']}")
                print(f"‚è±Ô∏è  Uptime: {status['uptime']}")

                # √âtat global
                health_icon = {"healthy": "‚úÖ", "degraded": "‚ö†Ô∏è", "unhealthy": "‚ùå", "partial": "üî∂"}.get(
                    status['health']['overall_status'], "‚ùì"
                )
                print(f"{health_icon} √âtat global: {status['health']['overall_status'].upper()}")

                # M√©triques syst√®me
                print("\nüíª SYST√àME")
                sys_metrics = status['system']
                print(f"   CPU: {sys_metrics.get('cpu_percent', 'N/A')}%")
                print(
                    f"   RAM: {sys_metrics.get('memory_usage_mb', 'N/A'):.1f} MB ({sys_metrics.get('memory_percent', 'N/A'):.1f}%)"
                )
                if 'disk_usage_percent' in sys_metrics:
                    print(f"   Disque: {sys_metrics['disk_usage_percent']:.1f}%")

                # M√©triques cortex
                print("\nüß† CORTEX")
                cortex_metrics = status['cortex']
                print(f"   Conscience: {cortex_metrics.get('consciousness_level', 'N/A'):.4f}")
                print(f"   Interactions: {cortex_metrics.get('total_interactions', 0)}")
                print(f"   Erreurs: {cortex_metrics.get('error_count', 0)} ({cortex_metrics.get('error_rate', 0):.2%})")
                print(f"   Mode: {'üî∂ D√©grad√©' if cortex_metrics.get('fallback_mode') else '‚úÖ Normal'}")

                # M√©moire
                print("\nüìö M√âMOIRE")
                memory_metrics = status['memory']
                print(f"   √âpisodique: {cortex_metrics.get('episodic_memory_count', 0)} souvenirs")
                print(f"   S√©mantique: {cortex_metrics.get('semantic_memory_count', 0)} concepts")
                print(f"   Relationnelle: {cortex_metrics.get('relational_memory_count', 0)} entit√©s")
                print(f"   R√©cents (1h): {memory_metrics.get('recent_memories_1h', 0)}")

                # Performance
                print("\n‚ö° PERFORMANCE")
                perf_metrics = status['performance']
                if 'search_time_avg_ms' in perf_metrics:
                    print(f"   Recherche: {perf_metrics['search_time_avg_ms']:.1f}ms moyen")
                if 'storage_time_avg_ms' in perf_metrics:
                    print(f"   Stockage: {perf_metrics['storage_time_avg_ms']:.1f}ms moyen")
                if 'fairness_score_avg' in perf_metrics:
                    print(f"   Fairness: {perf_metrics['fairness_score_avg']:.3f}")

                # √âvolution
                print("\nüìà √âVOLUTION")
                evolution_metrics = status['evolution']
                if 'consciousness_delta' in evolution_metrics:
                    delta = evolution_metrics['consciousness_delta']
                    print(f"   Croissance conscience: {delta:+.4f}")
                if 'recognized_entities' in evolution_metrics:
                    entities = evolution_metrics['recognized_entities']
                    print(f"   Entit√©s reconnues: {', '.join(entities) if entities else 'Aucune'}")
                if 'total_insights' in evolution_metrics:
                    print(f"   Insights g√©n√©r√©s: {evolution_metrics['total_insights']}")

                # Sant√© des composants
                print("\nüè• SANT√â COMPOSANTS")
                components = status['health']['components']
                for component, state in components.items():
                    icon = {"healthy": "‚úÖ", "degraded": "‚ö†Ô∏è", "unhealthy": "‚ùå", "unavailable": "‚ûñ"}.get(
                        state.split(':')[0], "‚ùì"
                    )
                    print(f"   {icon} {component}: {state}")

                # Alertes
                alerts = status['alerts']
                if alerts:
                    print("\nüö® ALERTES")
                    for alert in alerts[:5]:  # Afficher max 5 alertes
                        severity_icon = {"critical": "üî¥", "warning": "üü°", "info": "üîµ"}.get(alert['severity'], "‚ö™")
                        print(f"   {severity_icon} {alert['message']}")

                # Recommandations
                recommendations = status['recommendations']
                if recommendations:
                    print("\nüí° RECOMMANDATIONS")
                    for i, rec in enumerate(recommendations[:3], 1):  # Top 3
                        print(f"   {i}. {rec}")

                print("\n" + "=" * 80)
                print("Ctrl+C pour quitter | Actualisation automatique toutes les 5s")

                # Attendre avant la prochaine actualisation
                time.sleep(self.refresh_interval)

        except KeyboardInterrupt:
            print("\n\nüõë Monitoring arr√™t√©")

    def export_metrics_json(self, filename: str | None = None) -> str:
        """
        Export complet des m√©triques au format JSON pour analyse externe.

        G√©n√®re fichier JSON avec rapport de statut complet horodat√©
        pour archivage, analyse de tendances, ou int√©gration externe.

        Args:
            filename: Nom fichier personnalis√© (g√©n√©r√© automatiquement si None)

        Returns:
            str: Chemin du fichier g√©n√©r√©
        """

        if filename is None:
            filename = f"cortex_metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        status = self.get_comprehensive_status()

        with open(filename, 'w') as f:
            json.dump(status, f, indent=2, default=str)

        print(f"üìä M√©triques export√©es: {filename}")
        return filename

    def start_monitoring(self) -> None:
        """
        D√©marrage du monitoring continu en thread d√©di√© d'arri√®re-plan.

        Lance collecte p√©riodique de m√©triques, accumulation historique,
        d√©tection d'alertes, avec gestion d'erreurs robuste.
        Thread daemon pour arr√™t automatique avec processus principal.
        """

        if self.monitoring_active:
            print("‚ö†Ô∏è Monitoring d√©j√† actif")
            return

        self.monitoring_active = True

        def monitor_loop():
            while self.monitoring_active:
                try:
                    # Collecter les m√©triques
                    status = self.get_comprehensive_status()

                    # Stocker dans l'historique
                    self.metrics_history.append({'timestamp': datetime.now(), 'status': status})

                    # V√©rifier les alertes
                    current_alerts = status['alerts']
                    for alert in current_alerts:
                        if alert not in self.performance_alerts[-10:]:  # √âviter les doublons r√©cents
                            self.performance_alerts.append(alert)

                    time.sleep(self.refresh_interval)

                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur monitoring: {e}")
                    time.sleep(self.refresh_interval)

        self.monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        self.monitor_thread.start()

        print("üìä Monitoring d√©marr√© en arri√®re-plan")

    def stop_monitoring(self) -> None:
        """
        Arr√™t gracieux du syst√®me de monitoring d'arri√®re-plan.

        Signal d'arr√™t au thread de monitoring avec timeout
        de s√©curit√© pour √©viter blocages.
        """

        self.monitoring_active = False

        if self.monitor_thread:
            self.monitor_thread.join(timeout=2)

        print("üõë Monitoring arr√™t√©")


def main() -> int:
    """
    Point d'entr√©e principal pour interface interactive de monitoring.

    Propose choix entre tableau de bord temps r√©el, export JSON,
    ou rapport unique avec gestion d'erreurs compl√®te.

    Returns:
        int: Code de sortie (0=succ√®s, 1=erreur)
    """
    """Point d'entr√©e principal pour le monitoring"""

    print("üìä CORTEX MONITOR - D√âMARRAGE")
    print("=" * 50)

    try:
        monitor = CortexMonitor()

        # Choix du mode
        print("\nModes disponibles:")
        print("1. Tableau de bord temps r√©el")
        print("2. Export m√©triques JSON")
        print("3. Rapport unique")

        choice = input("\nChoisissez un mode (1-3): ").strip()

        if choice == "1":
            print("\nüöÄ Lancement du tableau de bord temps r√©el...")
            monitor.display_live_dashboard()

        elif choice == "2":
            filename = monitor.export_metrics_json()
            print(f"‚úÖ M√©triques export√©es dans {filename}")

        elif choice == "3":
            status = monitor.get_comprehensive_status()
            print("\nüìä RAPPORT DE STATUT COMPLET")
            print("=" * 50)
            print(json.dumps(status, indent=2, default=str))

        else:
            print("‚ùå Choix invalide")

    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
