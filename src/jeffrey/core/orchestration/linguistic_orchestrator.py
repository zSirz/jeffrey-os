"""
Linguistic Orchestrator
=====================

Integrates the linguistic memory system into Jeffrey's main orchestration layer,
providing language learning capabilities across all interaction modes.

This module:
1. Monitors all text channels for learning opportunities
2. Enriches text generation with learned phrases/patterns
3. Provides offline linguistic capabilities to multiple subsystems
4. Manages the linguistic learning lifecycle
"""

from __future__ import annotations

import logging
from typing import Any

# Import core components
from jeffrey.core.memory.linguistic_memory_manager import LinguisticMemoryManager
from jeffrey.core.voice.voice_linguistic_integration import VoiceLinguisticIntegration

# Create logger
logger = logging.getLogger(__name__)


class LinguisticOrchestrator:
    """Orchestrates linguistic memory integration across Jeffrey's systems."""

    def __init__(
        self,
        memory_manager: LinguisticMemoryManager | None = None,
        voice_integration: VoiceLinguisticIntegration | None = None,
        learning_enabled: bool = True,
    ):
        """Initialize the linguistic orchestrator.

        Args:
            memory_manager: Linguistic memory manager instance
            voice_integration: Voice linguistic integration instance
            learning_enabled: Whether linguistic learning is enabled
        """
        # Initialize components
        self.memory_manager = memory_manager or LinguisticMemoryManager()
        self.voice_integration = voice_integration or VoiceLinguisticIntegration(linguistic_memory=self.memory_manager)

        # Configuration
        self.learning_enabled = learning_enabled
        self.api_learning_enabled = False  # More restrictive for API content

        logger.info("Linguistic orchestrator initialized")

        # Log initial stats
        stats = self.memory_manager.get_stats()
        logger.info(
            f"Loaded linguistic memory with {stats['total_phrases']} phrases and {stats['total_unique_words']} words"
        )

    def process_jeffrey_output(self, text: str, channel: str = "text", metadata: dict = None) -> None:
        """Process text output from Jeffrey for linguistic learning.

        Args:
            text: Text generated by Jeffrey
            channel: Output channel ("text", "voice", etc.)
            metadata: Additional metadata about the output
        """
        if not self.learning_enabled:
            return

        # Add to linguistic memory
        self.memory_manager.add_phrase("jeffrey", text)

        # If this is voice output, also register with voice system
        if channel == "voice" and self.voice_integration:
            emotion = metadata.get("emotion", "neutre") if metadata else "neutre"
            self.voice_integration.register_jeffrey_speech(text, emotion)

    def process_user_input(self, text: str, channel: str = "text", metadata: dict = None) -> None:
        """Process text input from the user for linguistic learning.

        Args:
            text: Text from the user
            channel: Input channel ("text", "voice", etc.)
            metadata: Additional metadata about the input
        """
        if not self.learning_enabled:
            return

        # Add to linguistic memory
        self.memory_manager.add_phrase("user", text)

        # If this is voice input, also register with voice system
        if channel == "voice" and self.voice_integration:
            self.voice_integration.register_user_speech(text)

    def process_api_response(self, text: str, api_name: str, context: dict = None) -> None:
        """Process text from an API response for linguistic learning.

        Args:
            text: Text from the API
            api_name: Name of the API
            context: Context of the API call
        """
        if not self.learning_enabled or not self.api_learning_enabled:
            return

        # API responses are more restrictive due to potential copyright/privacy concerns
        # Only record if explicitly enabled
        self.memory_manager.add_phrase("api", text)

    def enrich_prompt(self, prompt: str, context: dict = None) -> str:
        """Enrich a prompt with linguistic context from memory.

        Args:
            prompt: The original prompt
            context: Additional context for enrichment

        Returns:
            Enriched prompt with linguistic context
        """
        # Find related phrases in memory
        similar_phrases = self.memory_manager.get_similar_phrases(prompt, threshold=0.5, limit=3)

        # If we have similar phrases, add context
        if similar_phrases:
            # Extract the most similar phrase
            most_similar = similar_phrases[0]["text"]

            # Simple enrichment - in a real system this would be more sophisticated
            enriched = f'{prompt}\n\nContexte linguistique: Dans un contexte similaire, j\'ai déjà utilisé des formulations comme: "{most_similar}"'
            return enriched

        return prompt

    def optimize_offline_response(self, text: str) -> str:
        """Optimize text for offline response generation using linguistic memory.

        Args:
            text: The text to optimize

        Returns:
            Optimized text for offline response
        """
        if self.voice_integration:
            optimized_text, _ = self.voice_integration.optimize_offline_speech(text)
            return optimized_text
        return text

    def get_similar_expressions(self, text: str, limit: int = 5) -> list[dict]:
        """Get expressions similar to the input text from linguistic memory.

        Args:
            text: The input text
            limit: Maximum number of results

        Returns:
            List of similar expressions with metadata
        """
        return self.memory_manager.get_similar_phrases(text, limit=limit)

    def get_dictionary_stats(self) -> dict[str, Any]:
        """Get statistics about the linguistic dictionary.

        Returns:
            Dictionary statistics
        """
        stats = self.memory_manager.get_stats()

        # Add orchestrator-specific stats
        stats.update(
            {
                "learning_enabled": self.learning_enabled,
                "api_learning_enabled": self.api_learning_enabled,
            }
        )

        # Add voice integration stats if available
        if self.voice_integration:
            voice_stats = self.voice_integration.get_linguistic_stats()
            stats["voice_integration"] = voice_stats.get("cache_integration", {})

        return stats

    def toggle_learning(self, enabled: bool) -> None:
        """Toggle linguistic learning on or off.

        Args:
            enabled: Whether learning should be enabled
        """
        self.learning_enabled = enabled
        logger.info(f"Linguistic learning {'enabled' if enabled else 'disabled'}")

    def toggle_api_learning(self, enabled: bool) -> None:
        """Toggle learning from API responses on or off.

        Args:
            enabled: Whether API learning should be enabled
        """
        self.api_learning_enabled = enabled
        logger.info(f"API linguistic learning {'enabled' if enabled else 'disabled'}")

    def clear_user_data(self) -> int:
        """Clear all user-sourced linguistic data.

        Returns:
            Number of user phrases removed
        """
        removed = self.memory_manager.clear_user_phrases()
        logger.info(f"Cleared {removed} user phrases from linguistic memory")
        return removed

    def save_state(self) -> None:
        """Save the current state of linguistic memory."""
        self.memory_manager.save()
        logger.info("Linguistic memory state saved")

    def initialize_subsystems(self) -> None:
        """Initialize linguistic memory integration with other subsystems."""
        # Enhance offline cache if available
        if self.voice_integration:
            words_added = self.voice_integration.enhance_offline_cache()
            logger.info(f"Enhanced offline voice cache with {words_added} priority words")

    def shutdown(self) -> None:
        """Clean up resources and save state when shutting down."""
        self.save_state()
        logger.info("Linguistic orchestrator shutdown complete")
