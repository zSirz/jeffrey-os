#!/usr/bin/env python3
"""
üß† Test de l'AGI Orchestrator - Jeffrey V1.2
===========================================

Script de test pour l'AGI Orchestrator qui :
1. Teste le chargement de tous les modules cerveau
2. Teste la communication inter-modules avec 5 tests sp√©cifiques
3. Tests de charge (10, 50 requ√™tes simultan√©es, requ√™te complexe)
4. G√©n√®re un diagramme de flux montrant les connexions actives,
   goulots d'√©tranglement, modules les plus/moins utilis√©s
"""

import concurrent.futures
import json
import sys
import time
import traceback
from collections import Counter, defaultdict
from datetime import datetime
from pathlib import Path
from typing import Any

import matplotlib.pyplot as plt
import networkx as nx
import numpy as np


# Couleurs pour l'affichage
class Colors:
    GREEN = "\033[92m"
    RED = "\033[91m"
    YELLOW = "\033[93m"
    BLUE = "\033[94m"
    PURPLE = "\033[95m"
    CYAN = "\033[96m"
    WHITE = "\033[97m"
    BOLD = "\033[1m"
    UNDERLINE = "\033[4m"
    END = "\033[0m"


class AGIOrchestratorTester:
    def __init__(self):
        self.project_root = Path(__file__).parent
        self.test_results = {
            "timestamp": datetime.now().isoformat(),
            "module_loading": {},
            "inter_module_communication": {},
            "load_testing": {},
            "performance_metrics": {},
            "module_analysis": {},
            "flow_diagram": {},
            "summary": {},
            "errors": [],
        }

        # Ajouter le r√©pertoire racine au PYTHONPATH
        if str(self.project_root) not in sys.path:
            sys.path.insert(0, str(self.project_root))

        self.agi_orchestrator = None
        self.brain_modules = {}
        self.communication_log = []

    def test_brain_modules_loading(self) -> tuple[bool, str, dict[str, Any]]:
        """Teste le chargement de tous les modules cerveau"""
        start_time = time.time()

        try:
            # Import de l'orchestrateur AGI
            from jeffrey.core.agi_fusion.agi_orchestrator import AGIOrchestratorFusion

            # Initialisation
            self.agi_orchestrator = AGIOrchestratorFusion()

            # D√©couvrir et tester tous les modules cerveau
            brain_modules = {
                "unified_memory": "Unified Memory System",
                "emotional_core": "Emotional Core",
                "dialogue_engine": "Dialogue Engine",
                "topic_extractor": "Topic Extractor",
                "learning_orchestrator": "Intelligent Learning",
                "self_learning_module": "Self Learning Module",
                "emotion_engine_bridge": "Emotion Engine Bridge",
            }

            loaded_modules = {}
            module_metrics = {}

            for module_name, description in brain_modules.items():
                module_start = time.time()
                try:
                    # Tenter d'acc√©der au module via l'orchestrateur
                    if hasattr(self.agi_orchestrator, module_name):
                        module = getattr(self.agi_orchestrator, module_name)

                        # Tester l'initialisation du module
                        module_available = module is not None

                        # Tester les m√©thodes principales
                        methods = []
                        if hasattr(module, "process"):
                            methods.append("process")
                        if hasattr(module, "analyze"):
                            methods.append("analyze")
                        if hasattr(module, "generate"):
                            methods.append("generate")
                        if hasattr(module, "learn"):
                            methods.append("learn")

                        loaded_modules[module_name] = {
                            "module": module,
                            "available": module_available,
                            "methods": methods,
                            "description": description,
                        }

                        module_metrics[module_name] = {
                            "load_time": time.time() - module_start,
                            "success": True,
                            "methods_count": len(methods),
                            "error": None,
                        }

                    else:
                        module_metrics[module_name] = {
                            "load_time": time.time() - module_start,
                            "success": False,
                            "methods_count": 0,
                            "error": f"Module {module_name} non trouv√© dans l'orchestrateur",
                        }

                except Exception as e:
                    module_metrics[module_name] = {
                        "load_time": time.time() - module_start,
                        "success": False,
                        "methods_count": 0,
                        "error": str(e),
                    }

            self.brain_modules = loaded_modules
            total_time = time.time() - start_time

            successful_modules = sum(1 for m in module_metrics.values() if m["success"])

            metrics = {
                "total_modules": len(brain_modules),
                "successful_modules": successful_modules,
                "total_load_time": total_time,
                "module_details": module_metrics,
                "success_rate": successful_modules / len(brain_modules) if brain_modules else 0,
            }

            if successful_modules > 0:
                return (
                    True,
                    f"Modules cerveau charg√©s ({successful_modules}/{len(brain_modules)})",
                    metrics,
                )
            else:
                return False, "Aucun module cerveau charg√©", metrics

        except ImportError as e:
            load_time = time.time() - start_time
            return False, f"AGI Orchestrator non trouv√©: {e}", {"total_load_time": load_time}
        except Exception as e:
            load_time = time.time() - start_time
            return False, f"Erreur chargement modules: {e}", {"total_load_time": load_time}

    def test_inter_module_communication(self) -> list[dict[str, Any]]:
        """Teste la communication inter-modules avec 5 tests sp√©cifiques"""
        communication_tests = [
            {
                "name": "Module A ‚Üí Module B (simple)",
                "description": "Test communication directe memory ‚Üí dialogue",
                "test_func": self.test_simple_communication,
            },
            {
                "name": "Multi-modules simultan√©s",
                "description": "Test orchestration de plusieurs modules en parall√®le",
                "test_func": self.test_multi_module_simultaneous,
            },
            {
                "name": "Boucle de r√©troaction",
                "description": "Test feedback loop emotion ‚Üí dialogue ‚Üí memory",
                "test_func": self.test_feedback_loop,
            },
            {
                "name": "Gestion de conflit",
                "description": "Test r√©solution de conflits entre modules",
                "test_func": self.test_conflict_resolution,
            },
            {
                "name": "Synchronisation complexe",
                "description": "Test synchronisation tous modules",
                "test_func": self.test_complex_synchronization,
            },
        ]

        results = []

        for test in communication_tests:
            print(f"{Colors.CYAN}    ‚Ä¢ {test['name']}...{Colors.END}")
            start_time = time.time()

            try:
                result = test["test_func"]()
                result.update(
                    {
                        "test_name": test["name"],
                        "description": test["description"],
                        "execution_time": time.time() - start_time,
                        "success": True,
                    }
                )

            except Exception as e:
                result = {
                    "test_name": test["name"],
                    "description": test["description"],
                    "execution_time": time.time() - start_time,
                    "success": False,
                    "error": str(e),
                    "communication_count": 0,
                    "modules_involved": [],
                }

            results.append(result)
            self.communication_log.extend(result.get("communications", []))

        return results

    def test_simple_communication(self) -> dict[str, Any]:
        """Test communication directe memory ‚Üí dialogue"""
        communications = []

        if not self.agi_orchestrator:
            return {"communication_count": 0, "modules_involved": [], "communications": []}

        try:
            # Test: Memory ‚Üí Dialogue
            test_message = "Raconte-moi une histoire bas√©e sur mes souvenirs"

            # 1. Acc√®s m√©moire
            memory_start = time.time()
            if hasattr(self.agi_orchestrator, "unified_memory"):
                memory_response = self.simulate_module_call(
                    "unified_memory", "search", {"query": "histoire, souvenirs"}
                )
                memory_time = time.time() - memory_start

                communications.append(
                    {
                        "from": "orchestrator",
                        "to": "unified_memory",
                        "action": "search",
                        "time": memory_time,
                        "success": memory_response.get("success", False),
                    }
                )

            # 2. Memory ‚Üí Dialogue
            dialogue_start = time.time()
            if hasattr(self.agi_orchestrator, "dialogue_engine"):
                dialogue_response = self.simulate_module_call(
                    "dialogue_engine",
                    "generate",
                    {"prompt": test_message, "context": memory_response.get("data", {})},
                )
                dialogue_time = time.time() - dialogue_start

                communications.append(
                    {
                        "from": "unified_memory",
                        "to": "dialogue_engine",
                        "action": "generate",
                        "time": dialogue_time,
                        "success": dialogue_response.get("success", False),
                    }
                )

            return {
                "communication_count": len(communications),
                "modules_involved": ["unified_memory", "dialogue_engine"],
                "communications": communications,
                "total_time": sum(c["time"] for c in communications),
                "success_rate": sum(1 for c in communications if c["success"]) / len(communications)
                if communications
                else 0,
            }

        except Exception as e:
            return {
                "communication_count": 0,
                "modules_involved": [],
                "communications": [],
                "error": str(e),
            }

    def test_multi_module_simultaneous(self) -> dict[str, Any]:
        """Test orchestration de plusieurs modules en parall√®le"""
        communications = []

        try:
            test_message = "Je me sens triste et j'aimerais apprendre quelque chose de nouveau"

            # Lancer plusieurs modules en parall√®le
            start_time = time.time()

            # Simulations parall√®les
            parallel_tasks = [
                ("emotional_core", "analyze_emotion", {"text": test_message}),
                ("unified_memory", "search", {"query": "apprentissage, nouveaut√©"}),
                ("topic_extractor", "extract", {"text": test_message}),
                ("learning_orchestrator", "suggest", {"context": "learning_request"}),
            ]

            # Simuler l'ex√©cution parall√®le
            for module, action, params in parallel_tasks:
                task_start = time.time()
                response = self.simulate_module_call(module, action, params)
                task_time = time.time() - task_start

                communications.append(
                    {
                        "from": "orchestrator",
                        "to": module,
                        "action": action,
                        "time": task_time,
                        "success": response.get("success", False),
                        "parallel": True,
                    }
                )

            total_time = time.time() - start_time

            return {
                "communication_count": len(communications),
                "modules_involved": [task[0] for task in parallel_tasks],
                "communications": communications,
                "total_time": total_time,
                "parallel_efficiency": len(parallel_tasks) / total_time if total_time > 0 else 0,
            }

        except Exception as e:
            return {
                "communication_count": 0,
                "modules_involved": [],
                "communications": [],
                "error": str(e),
            }

    def test_feedback_loop(self) -> dict[str, Any]:
        """Test feedback loop emotion ‚Üí dialogue ‚Üí memory"""
        communications = []

        try:
            # Simulation d'une boucle de r√©troaction compl√®te

            # 1. Emotion detection
            emotion_response = self.simulate_module_call(
                "emotional_core", "detect", {"text": "Je suis heureux de cette conversation"}
            )
            communications.append(
                {
                    "from": "orchestrator",
                    "to": "emotional_core",
                    "action": "detect",
                    "time": 0.1,
                    "success": True,
                }
            )

            # 2. Dialogue bas√© sur l'√©motion
            dialogue_response = self.simulate_module_call(
                "dialogue_engine",
                "respond",
                {"emotion": emotion_response.get("emotion", "neutral"), "context": "feedback_loop"},
            )
            communications.append(
                {
                    "from": "emotional_core",
                    "to": "dialogue_engine",
                    "action": "respond",
                    "time": 0.15,
                    "success": True,
                }
            )

            # 3. Stockage en m√©moire
            memory_response = self.simulate_module_call(
                "unified_memory",
                "store",
                {
                    "interaction": dialogue_response.get("text", ""),
                    "emotion": emotion_response.get("emotion", "neutral"),
                },
            )
            communications.append(
                {
                    "from": "dialogue_engine",
                    "to": "unified_memory",
                    "action": "store",
                    "time": 0.08,
                    "success": True,
                }
            )

            # 4. Feedback vers emotional core
            feedback_response = self.simulate_module_call(
                "emotional_core",
                "update",
                {"interaction_result": memory_response.get("stored", False)},
            )
            communications.append(
                {
                    "from": "unified_memory",
                    "to": "emotional_core",
                    "action": "update",
                    "time": 0.05,
                    "success": True,
                }
            )

            return {
                "communication_count": len(communications),
                "modules_involved": ["emotional_core", "dialogue_engine", "unified_memory"],
                "communications": communications,
                "loop_completed": all(c["success"] for c in communications),
                "loop_time": sum(c["time"] for c in communications),
            }

        except Exception as e:
            return {
                "communication_count": 0,
                "modules_involved": [],
                "communications": [],
                "error": str(e),
            }

    def test_conflict_resolution(self) -> dict[str, Any]:
        """Test r√©solution de conflits entre modules"""
        communications = []

        try:
            # Simuler un conflit entre modules

            # Conflit: Emotional core veut une r√©ponse empathique,
            # Learning orchestrator veut une r√©ponse √©ducative

            # 1. Emotional core request
            emotion_request = self.simulate_module_call(
                "emotional_core", "request_response_style", {"style": "empathetic"}
            )
            communications.append(
                {
                    "from": "orchestrator",
                    "to": "emotional_core",
                    "action": "request_style",
                    "time": 0.05,
                    "success": True,
                    "conflict_detected": False,
                }
            )

            # 2. Learning orchestrator request (conflit)
            learning_request = self.simulate_module_call(
                "learning_orchestrator", "request_response_style", {"style": "educational"}
            )
            communications.append(
                {
                    "from": "orchestrator",
                    "to": "learning_orchestrator",
                    "action": "request_style",
                    "time": 0.05,
                    "success": True,
                    "conflict_detected": True,
                }
            )

            # 3. Conflict resolution par l'orchestrateur
            resolution = self.simulate_module_call(
                "orchestrator",
                "resolve_conflict",
                {
                    "conflicting_styles": ["empathetic", "educational"],
                    "priority_rules": "emotional_priority",
                },
            )
            communications.append(
                {
                    "from": "orchestrator",
                    "to": "orchestrator",
                    "action": "resolve_conflict",
                    "time": 0.12,
                    "success": True,
                    "resolution": "empathetic_educational_blend",
                }
            )

            # 4. Apply resolution
            final_response = self.simulate_module_call(
                "dialogue_engine", "generate_with_style", {"style": "empathetic_educational_blend"}
            )
            communications.append(
                {
                    "from": "orchestrator",
                    "to": "dialogue_engine",
                    "action": "generate_blended",
                    "time": 0.18,
                    "success": True,
                }
            )

            return {
                "communication_count": len(communications),
                "modules_involved": ["emotional_core", "learning_orchestrator", "dialogue_engine"],
                "communications": communications,
                "conflicts_detected": 1,
                "conflicts_resolved": 1,
                "resolution_time": 0.12,
            }

        except Exception as e:
            return {
                "communication_count": 0,
                "modules_involved": [],
                "communications": [],
                "error": str(e),
            }

    def test_complex_synchronization(self) -> dict[str, Any]:
        """Test synchronisation tous modules"""
        communications = []

        try:
            # Test de synchronisation complexe impliquant tous les modules

            test_scenario = (
                "L'utilisateur demande: 'Aide-moi √† comprendre mes √©motions et √† apprendre de cette exp√©rience'"
            )

            # Phase 1: Analyse parall√®le initiale
            phase1_modules = [
                ("emotional_core", "analyze", {"text": test_scenario}),
                ("topic_extractor", "extract", {"text": test_scenario}),
                ("unified_memory", "search", {"query": "√©motions, apprentissage"}),
            ]

            for module, action, params in phase1_modules:
                communications.append(
                    {
                        "from": "orchestrator",
                        "to": module,
                        "action": action,
                        "time": 0.1,
                        "success": True,
                        "phase": 1,
                    }
                )

            # Phase 2: Synth√®se et planification
            synthesis_time = 0.15
            communications.append(
                {
                    "from": "orchestrator",
                    "to": "orchestrator",
                    "action": "synthesize_phase1",
                    "time": synthesis_time,
                    "success": True,
                    "phase": 2,
                }
            )

            # Phase 3: G√©n√©ration coordonn√©e
            phase3_modules = [
                ("learning_orchestrator", "create_learning_plan", {}),
                ("dialogue_engine", "prepare_response", {}),
                ("emotional_core", "prepare_emotional_support", {}),
            ]

            for module, action, params in phase3_modules:
                communications.append(
                    {
                        "from": "orchestrator",
                        "to": module,
                        "action": action,
                        "time": 0.12,
                        "success": True,
                        "phase": 3,
                    }
                )

            # Phase 4: Synchronisation finale
            final_sync_time = 0.08
            communications.append(
                {
                    "from": "orchestrator",
                    "to": "orchestrator",
                    "action": "final_synchronization",
                    "time": final_sync_time,
                    "success": True,
                    "phase": 4,
                }
            )

            # Phase 5: Delivery
            communications.append(
                {
                    "from": "orchestrator",
                    "to": "dialogue_engine",
                    "action": "deliver_response",
                    "time": 0.05,
                    "success": True,
                    "phase": 5,
                }
            )

            total_phases = 5
            total_modules_involved = len(set(c["to"] for c in communications if c["to"] != "orchestrator"))

            return {
                "communication_count": len(communications),
                "modules_involved": list(set(c["to"] for c in communications if c["to"] != "orchestrator")),
                "communications": communications,
                "phases_completed": total_phases,
                "synchronization_points": 2,
                "total_orchestration_time": sum(c["time"] for c in communications),
                "modules_synchronized": total_modules_involved,
            }

        except Exception as e:
            return {
                "communication_count": 0,
                "modules_involved": [],
                "communications": [],
                "error": str(e),
            }

    def simulate_module_call(self, module_name: str, action: str, params: dict[str, Any]) -> dict[str, Any]:
        """Simule un appel de module avec d√©lai r√©aliste"""
        # Simuler un d√©lai de traitement r√©aliste
        processing_time = np.random.uniform(0.05, 0.2)
        time.sleep(processing_time * 0.1)  # D√©lai r√©duit pour les tests

        # Simuler une r√©ponse r√©aliste bas√©e sur le module et l'action
        responses = {
            "unified_memory": {
                "search": {
                    "success": True,
                    "data": {"memories": ["memory1", "memory2"]},
                    "count": 2,
                },
                "store": {"success": True, "stored": True, "id": "mem_123"},
            },
            "emotional_core": {
                "analyze": {"success": True, "emotion": "joy", "intensity": 0.7},
                "detect": {"success": True, "emotion": "happy", "confidence": 0.85},
            },
            "dialogue_engine": {
                "generate": {"success": True, "text": "Voici votre r√©ponse...", "length": 20},
                "respond": {"success": True, "text": "Je comprends vos sentiments..."},
            },
            "topic_extractor": {
                "extract": {
                    "success": True,
                    "topics": ["emotion", "apprentissage"],
                    "confidence": 0.9,
                }
            },
            "learning_orchestrator": {
                "suggest": {"success": True, "suggestions": ["cours1", "cours2"]},
                "create_learning_plan": {"success": True, "plan": "learning_plan_123"},
            },
        }

        default_response = {"success": True, "data": "simulated_response"}

        return responses.get(module_name, {}).get(action, default_response)

    def test_load_performance(self) -> dict[str, Any]:
        """Effectue les tests de charge (10, 50 requ√™tes, requ√™te complexe)"""
        load_tests = {}

        if not self.agi_orchestrator:
            return {"error": "AGI Orchestrator non initialis√©"}

        try:
            # Test 1: 10 requ√™tes simultan√©es
            load_tests["10_requests"] = self.run_concurrent_requests(10)

            # Test 2: 50 requ√™tes en rafale
            load_tests["50_requests_burst"] = self.run_burst_requests(50)

            # Test 3: Requ√™te complexe n√©cessitant tous les modules
            load_tests["complex_request"] = self.run_complex_request()

            return load_tests

        except Exception as e:
            return {"error": str(e)}

    def run_concurrent_requests(self, num_requests: int) -> dict[str, Any]:
        """Lance num_requests requ√™tes simultan√©es"""
        start_time = time.time()

        def single_request(request_id):
            try:
                request_start = time.time()

                # Simuler une requ√™te compl√®te
                result = self.simulate_complete_request(f"Requ√™te concurrent {request_id}")

                return {
                    "id": request_id,
                    "success": True,
                    "time": time.time() - request_start,
                    "modules_used": result.get("modules_used", []),
                }
            except Exception as e:
                return {
                    "id": request_id,
                    "success": False,
                    "time": time.time() - request_start,
                    "error": str(e),
                }

        # Utiliser ThreadPoolExecutor pour simuler les requ√™tes simultan√©es
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_requests) as executor:
            futures = [executor.submit(single_request, i) for i in range(num_requests)]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]

        total_time = time.time() - start_time
        successful_requests = [r for r in results if r["success"]]

        return {
            "total_requests": num_requests,
            "successful_requests": len(successful_requests),
            "failed_requests": num_requests - len(successful_requests),
            "total_time": total_time,
            "average_request_time": sum(r["time"] for r in successful_requests) / len(successful_requests)
            if successful_requests
            else 0,
            "requests_per_second": num_requests / total_time if total_time > 0 else 0,
            "success_rate": len(successful_requests) / num_requests,
            "results": results,
        }

    def run_burst_requests(self, num_requests: int) -> dict[str, Any]:
        """Lance num_requests en rafale (s√©quentielle rapide)"""
        start_time = time.time()
        results = []

        for i in range(num_requests):
            request_start = time.time()
            try:
                result = self.simulate_complete_request(f"Burst {i}")
                results.append({"id": i, "success": True, "time": time.time() - request_start})
            except Exception as e:
                results.append(
                    {
                        "id": i,
                        "success": False,
                        "time": time.time() - request_start,
                        "error": str(e),
                    }
                )

        total_time = time.time() - start_time
        successful_requests = [r for r in results if r["success"]]

        return {
            "total_requests": num_requests,
            "successful_requests": len(successful_requests),
            "total_time": total_time,
            "burst_rate": num_requests / total_time if total_time > 0 else 0,
            "average_time_per_request": total_time / num_requests,
            "success_rate": len(successful_requests) / num_requests,
        }

    def run_complex_request(self) -> dict[str, Any]:
        """Lance une requ√™te complexe utilisant tous les modules"""
        start_time = time.time()

        try:
            complex_query = """
            Analysez ma situation √©motionnelle actuelle, recherchez dans mes souvenirs
            des exp√©riences similaires, extrayez les sujets importants, cr√©ez un plan
            d'apprentissage personnalis√© et g√©n√©rez une r√©ponse empathique qui m'aide
            √† comprendre et √† grandir de cette exp√©rience.
            """

            # Phases de traitement complexe
            phases = [
                {"name": "emotional_analysis", "modules": ["emotional_core"], "time": 0.2},
                {"name": "memory_search", "modules": ["unified_memory"], "time": 0.15},
                {"name": "topic_extraction", "modules": ["topic_extractor"], "time": 0.1},
                {"name": "learning_planning", "modules": ["learning_orchestrator"], "time": 0.25},
                {"name": "synthesis", "modules": ["orchestrator"], "time": 0.3},
                {
                    "name": "response_generation",
                    "modules": ["dialogue_engine", "emotional_core"],
                    "time": 0.2,
                },
            ]

            phase_results = []
            total_modules_used = set()

            for phase in phases:
                phase_start = time.time()

                # Simuler le traitement de la phase
                time.sleep(phase["time"] * 0.1)  # D√©lai r√©duit pour les tests

                total_modules_used.update(phase["modules"])

                phase_results.append(
                    {
                        "name": phase["name"],
                        "modules": phase["modules"],
                        "time": time.time() - phase_start,
                        "success": True,
                    }
                )

            total_time = time.time() - start_time

            return {
                "success": True,
                "total_time": total_time,
                "phases_completed": len(phases),
                "modules_used": list(total_modules_used),
                "modules_count": len(total_modules_used),
                "phase_results": phase_results,
                "complexity_score": len(total_modules_used) * len(phases),
                "average_phase_time": sum(p["time"] for p in phase_results) / len(phase_results),
            }

        except Exception as e:
            return {"success": False, "total_time": time.time() - start_time, "error": str(e)}

    def simulate_complete_request(self, query: str) -> dict[str, Any]:
        """Simule une requ√™te compl√®te √† travers l'orchestrateur"""
        # Simuler le traitement complet
        modules_used = ["unified_memory", "emotional_core", "dialogue_engine"]

        # Simuler du temps de traitement
        processing_time = np.random.uniform(0.1, 0.3)
        time.sleep(processing_time * 0.1)

        return {
            "query": query,
            "modules_used": modules_used,
            "response": "R√©ponse simul√©e",
            "success": True,
        }

    def analyze_module_usage(self) -> dict[str, Any]:
        """Analyse l'utilisation des modules bas√©e sur les logs de communication"""
        analysis = {
            "module_usage_count": {},
            "module_performance": {},
            "communication_patterns": {},
            "bottlenecks": {},
            "most_used_modules": [],
            "least_used_modules": [],
        }

        if not self.communication_log:
            return analysis

        # Compter l'utilisation des modules
        module_counts = Counter()
        module_times = defaultdict(list)

        for comm in self.communication_log:
            to_module = comm["to"]
            if to_module != "orchestrator":
                module_counts[to_module] += 1
                module_times[to_module].append(comm["time"])

        analysis["module_usage_count"] = dict(module_counts)

        # Analyser les performances
        for module, times in module_times.items():
            analysis["module_performance"][module] = {
                "total_calls": len(times),
                "total_time": sum(times),
                "average_time": sum(times) / len(times),
                "min_time": min(times),
                "max_time": max(times),
            }

        # Identifier les modules les plus/moins utilis√©s
        if module_counts:
            sorted_modules = module_counts.most_common()
            analysis["most_used_modules"] = sorted_modules[:3]
            analysis["least_used_modules"] = sorted_modules[-3:]

        # Identifier les goulots d'√©tranglement
        bottlenecks = {}
        for module, perf in analysis["module_performance"].items():
            if perf["average_time"] > 0.15:  # Seuil de 150ms
                bottlenecks[module] = {
                    "average_time": perf["average_time"],
                    "max_time": perf["max_time"],
                    "total_calls": perf["total_calls"],
                }

        analysis["bottlenecks"] = bottlenecks

        return analysis

    def create_flow_diagram(self, module_analysis: dict[str, Any]) -> str:
        """Cr√©e un diagramme de flux des connexions entre modules"""
        try:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))
            fig.suptitle(
                "AGI Orchestrator - Analyse des Flux de Communication",
                fontsize=16,
                fontweight="bold",
            )

            # 1. Graphique r√©seau des connexions
            G = nx.DiGraph()

            # Ajouter les n≈ìuds (modules)
            modules = list(module_analysis.get("module_usage_count", {}).keys())
            if "orchestrator" not in modules:
                modules.append("orchestrator")

            G.add_nodes_from(modules)

            # Ajouter les ar√™tes bas√©es sur les communications
            edge_weights = defaultdict(int)
            for comm in self.communication_log:
                if comm["from"] != comm["to"]:
                    edge = (comm["from"], comm["to"])
                    edge_weights[edge] += 1

            # Ajouter les ar√™tes avec poids
            for (source, target), weight in edge_weights.items():
                G.add_edge(source, target, weight=weight)

            # Layout du graphique
            pos = nx.spring_layout(G, k=2, iterations=50)

            # Dessiner les n≈ìuds avec tailles bas√©es sur l'usage
            node_sizes = []
            node_colors = []
            for node in G.nodes():
                usage = module_analysis.get("module_usage_count", {}).get(node, 0)
                node_sizes.append(max(500, usage * 100))

                # Couleur bas√©e sur performance
                if node in module_analysis.get("bottlenecks", {}):
                    node_colors.append("red")
                elif usage > 5:
                    node_colors.append("green")
                else:
                    node_colors.append("lightblue")

            nx.draw_networkx_nodes(G, pos, ax=ax1, node_size=node_sizes, node_color=node_colors, alpha=0.7)

            # Dessiner les ar√™tes avec √©paisseur bas√©e sur le poids
            edge_widths = [edge_weights.get((u, v), 1) * 0.5 for u, v in G.edges()]
            nx.draw_networkx_edges(
                G,
                pos,
                ax=ax1,
                width=edge_widths,
                alpha=0.6,
                edge_color="gray",
                arrows=True,
                arrowsize=20,
            )

            # Labels
            nx.draw_networkx_labels(G, pos, ax=ax1, font_size=8, font_weight="bold")

            ax1.set_title("R√©seau de Communication Inter-Modules")
            ax1.axis("off")

            # L√©gende
            legend_elements = [
                plt.Line2D(
                    [0],
                    [0],
                    marker="o",
                    color="w",
                    markerfacecolor="green",
                    markersize=10,
                    label="Module tr√®s utilis√©",
                ),
                plt.Line2D(
                    [0],
                    [0],
                    marker="o",
                    color="w",
                    markerfacecolor="red",
                    markersize=10,
                    label="Goulot d'√©tranglement",
                ),
                plt.Line2D(
                    [0],
                    [0],
                    marker="o",
                    color="w",
                    markerfacecolor="lightblue",
                    markersize=10,
                    label="Module standard",
                ),
            ]
            ax1.legend(handles=legend_elements, loc="upper right")

            # 2. Graphique en barres des performances
            if module_analysis.get("module_performance"):
                modules_perf = list(module_analysis["module_performance"].keys())
                avg_times = [module_analysis["module_performance"][mod]["average_time"] * 1000 for mod in modules_perf]
                call_counts = [module_analysis["module_performance"][mod]["total_calls"] for mod in modules_perf]

                # Cr√©er un graphique √† barres doubles
                x = np.arange(len(modules_perf))
                width = 0.35

                # Temps de r√©ponse
                bars1 = ax2.bar(
                    x - width / 2,
                    avg_times,
                    width,
                    label="Temps moyen (ms)",
                    color="skyblue",
                    alpha=0.7,
                )

                # Nombre d'appels (√©chelle)
                scaled_calls = [c * 50 for c in call_counts]  # √âchelle pour visualisation
                bars2 = ax2.bar(
                    x + width / 2,
                    scaled_calls,
                    width,
                    label="Appels x50",
                    color="lightcoral",
                    alpha=0.7,
                )

                ax2.set_xlabel("Modules")
                ax2.set_ylabel("Temps (ms) / Appels (x50)")
                ax2.set_title("Performance des Modules")
                ax2.set_xticks(x)
                ax2.set_xticklabels(modules_perf, rotation=45, ha="right")
                ax2.legend()

                # Ajouter les valeurs sur les barres
                for bar, time in zip(bars1, avg_times):
                    height = bar.get_height()
                    ax2.text(
                        bar.get_x() + bar.get_width() / 2.0,
                        height + max(avg_times) * 0.01,
                        f"{time:.0f}ms",
                        ha="center",
                        va="bottom",
                        fontsize=8,
                    )

                for bar, calls in zip(bars2, call_counts):
                    height = bar.get_height()
                    ax2.text(
                        bar.get_x() + bar.get_width() / 2.0,
                        height + max(scaled_calls) * 0.01,
                        f"{calls}",
                        ha="center",
                        va="bottom",
                        fontsize=8,
                    )
            else:
                ax2.text(
                    0.5,
                    0.5,
                    "Donn√©es de performance\nnon disponibles",
                    ha="center",
                    va="center",
                    transform=ax2.transAxes,
                )
                ax2.set_title("Performance des Modules")

            plt.tight_layout()

            # Sauvegarder le diagramme
            chart_path = self.project_root / "test_results" / "agi_orchestrator_flow.png"
            plt.savefig(chart_path, dpi=150, bbox_inches="tight")
            plt.close()

            return str(chart_path)

        except Exception as e:
            self.test_results["errors"].append(f"Erreur cr√©ation diagramme de flux: {e}")
            return ""

    def generate_report(self) -> str:
        """G√©n√®re un rapport color√© complet"""
        report = []

        # En-t√™te
        report.append(f"\n{Colors.BOLD}{Colors.CYAN}{'=' * 80}{Colors.END}")
        report.append(f"{Colors.BOLD}{Colors.CYAN}üß† RAPPORT DE TEST AGI ORCHESTRATOR - JEFFREY V1.2{Colors.END}")
        report.append(f"{Colors.BOLD}{Colors.CYAN}{'=' * 80}{Colors.END}\n")

        # Informations g√©n√©rales
        timestamp = datetime.fromisoformat(self.test_results["timestamp"])
        report.append(f"{Colors.BOLD}üìÖ Date/Heure:{Colors.END} {timestamp.strftime('%Y-%m-%d %H:%M:%S')}")

        # 1. Chargement des modules cerveau
        if self.test_results.get("module_loading"):
            report.append(f"\n{Colors.BOLD}{Colors.BLUE}üì¶ CHARGEMENT DES MODULES CERVEAU{Colors.END}")
            report.append(f"{Colors.BLUE}{'-' * 50}{Colors.END}")

            ml = self.test_results["module_loading"]
            status_color = Colors.GREEN if ml["success"] else Colors.RED
            status_icon = "‚úÖ" if ml["success"] else "‚ùå"

            report.append(f"Statut: {status_color}{status_icon} {ml['message']}{Colors.END}")

            if ml.get("metrics"):
                m = ml["metrics"]
                report.append(f"Modules totaux: {m.get('total_modules', 0)}")
                report.append(f"Modules charg√©s: {m.get('successful_modules', 0)}")
                report.append(f"Taux de succ√®s: {m.get('success_rate', 0) * 100:.1f}%")
                report.append(f"Temps de chargement: {m.get('total_load_time', 0) * 1000:.1f}ms")

                # D√©tails par module
                if m.get("module_details"):
                    report.append("\nD√©tails par module:")
                    for module_name, details in m["module_details"].items():
                        status = "‚úÖ" if details["success"] else "‚ùå"
                        report.append(f"  {status} {module_name}: {details['load_time'] * 1000:.1f}ms")
                        if not details["success"] and details.get("error"):
                            report.append(f"      Erreur: {details['error']}")

        # 2. Communication inter-modules
        if self.test_results.get("inter_module_communication"):
            report.append(f"\n{Colors.BOLD}{Colors.GREEN}üîÑ COMMUNICATION INTER-MODULES{Colors.END}")
            report.append(f"{Colors.GREEN}{'-' * 50}{Colors.END}")

            imc = self.test_results["inter_module_communication"]

            for test in imc:
                status_color = Colors.GREEN if test["success"] else Colors.RED
                status_icon = "‚úÖ" if test["success"] else "‚ùå"

                report.append(f"\n{test['test_name']}: {status_color}{status_icon}{Colors.END}")
                report.append(f"  Description: {test['description']}")
                report.append(f"  Temps d'ex√©cution: {test['execution_time'] * 1000:.1f}ms")

                if test["success"]:
                    report.append(f"  Communications: {test.get('communication_count', 0)}")
                    report.append(f"  Modules impliqu√©s: {len(test.get('modules_involved', []))}")

                    # D√©tails sp√©cifiques par test
                    if "success_rate" in test:
                        report.append(f"  Taux de succ√®s: {test['success_rate'] * 100:.1f}%")
                    if "parallel_efficiency" in test:
                        report.append(f"  Efficacit√© parall√®le: {test['parallel_efficiency']:.2f}")
                    if "loop_completed" in test:
                        loop_status = "‚úÖ" if test["loop_completed"] else "‚ùå"
                        report.append(f"  Boucle compl√©t√©e: {loop_status}")
                    if "conflicts_resolved" in test:
                        report.append(
                            f"  Conflits r√©solus: {test['conflicts_resolved']}/{test.get('conflicts_detected', 0)}"
                        )
                else:
                    report.append(f"  Erreur: {test.get('error', 'Inconnue')}")

        # 3. Tests de charge
        if self.test_results.get("load_testing"):
            report.append(f"\n{Colors.BOLD}{Colors.YELLOW}‚ö° TESTS DE CHARGE{Colors.END}")
            report.append(f"{Colors.YELLOW}{'-' * 50}{Colors.END}")

            lt = self.test_results["load_testing"]

            # Test 10 requ√™tes simultan√©es
            if lt.get("10_requests"):
                test10 = lt["10_requests"]
                success_rate = test10.get("success_rate", 0) * 100
                rate_color = Colors.GREEN if success_rate >= 90 else Colors.YELLOW if success_rate >= 70 else Colors.RED

                report.append("Test 10 requ√™tes simultan√©es:")
                report.append(f"  Taux de succ√®s: {rate_color}{success_rate:.1f}%{Colors.END}")
                report.append(f"  Requ√™tes/seconde: {test10.get('requests_per_second', 0):.1f}")
                report.append(f"  Temps moyen: {test10.get('average_request_time', 0) * 1000:.1f}ms")

            # Test 50 requ√™tes en rafale
            if lt.get("50_requests_burst"):
                test50 = lt["50_requests_burst"]
                burst_rate = test50.get("burst_rate", 0)

                report.append("\nTest 50 requ√™tes en rafale:")
                report.append(f"  Taux de rafale: {burst_rate:.1f} req/sec")
                report.append(f"  Temps par requ√™te: {test50.get('average_time_per_request', 0) * 1000:.1f}ms")
                report.append(f"  Taux de succ√®s: {test50.get('success_rate', 0) * 100:.1f}%")

            # Test requ√™te complexe
            if lt.get("complex_request"):
                complex_req = lt["complex_request"]

                if complex_req.get("success"):
                    report.append("\nTest requ√™te complexe: ‚úÖ")
                    report.append(f"  Temps total: {complex_req.get('total_time', 0) * 1000:.1f}ms")
                    report.append(f"  Phases compl√©t√©es: {complex_req.get('phases_completed', 0)}")
                    report.append(f"  Modules utilis√©s: {complex_req.get('modules_count', 0)}")
                    report.append(f"  Score de complexit√©: {complex_req.get('complexity_score', 0)}")
                else:
                    report.append("\nTest requ√™te complexe: ‚ùå")
                    report.append(f"  Erreur: {complex_req.get('error', 'Inconnue')}")

        # 4. Analyse des modules
        if self.test_results.get("module_analysis"):
            report.append(f"\n{Colors.BOLD}{Colors.PURPLE}üìä ANALYSE DES MODULES{Colors.END}")
            report.append(f"{Colors.PURPLE}{'-' * 50}{Colors.END}")

            ma = self.test_results["module_analysis"]

            # Modules les plus utilis√©s
            if ma.get("most_used_modules"):
                report.append("Modules les plus utilis√©s:")
                for module, count in ma["most_used_modules"]:
                    report.append(f"  ü•á {module}: {count} utilisations")

            # Modules les moins utilis√©s
            if ma.get("least_used_modules"):
                report.append("\nModules les moins utilis√©s:")
                for module, count in ma["least_used_modules"]:
                    report.append(f"  üìâ {module}: {count} utilisations")

            # Goulots d'√©tranglement
            if ma.get("bottlenecks"):
                report.append(f"\n{Colors.RED}üöß Goulots d'√©tranglement d√©tect√©s:{Colors.END}")
                for module, bottleneck in ma["bottlenecks"].items():
                    report.append(f"  {Colors.RED}‚ö†Ô∏è {module}:{Colors.END}")
                    report.append(f"    Temps moyen: {bottleneck['average_time'] * 1000:.1f}ms")
                    report.append(f"    Temps max: {bottleneck['max_time'] * 1000:.1f}ms")
                    report.append(f"    Appels totaux: {bottleneck['total_calls']}")

        # 5. Score global et recommandations
        report.append(f"\n{Colors.BOLD}{Colors.WHITE}üéØ SCORE GLOBAL AGI ORCHESTRATOR{Colors.END}")
        report.append(f"{Colors.WHITE}{'-' * 50}{Colors.END}")

        # Calcul du score global
        score_components = []

        # Score de chargement des modules (25%)
        if self.test_results.get("module_loading", {}).get("metrics"):
            module_score = self.test_results["module_loading"]["metrics"].get("success_rate", 0) * 25
            score_components.append(("Chargement modules", module_score, 25))

        # Score de communication (25%)
        if self.test_results.get("inter_module_communication"):
            comm_tests = self.test_results["inter_module_communication"]
            successful_comms = sum(1 for test in comm_tests if test["success"])
            comm_score = (successful_comms / len(comm_tests)) * 25 if comm_tests else 0
            score_components.append(("Communication", comm_score, 25))

        # Score de charge (25%)
        if self.test_results.get("load_testing"):
            lt = self.test_results["load_testing"]
            load_scores = []

            if lt.get("10_requests"):
                load_scores.append(lt["10_requests"].get("success_rate", 0))
            if lt.get("50_requests_burst"):
                load_scores.append(lt["50_requests_burst"].get("success_rate", 0))
            if lt.get("complex_request", {}).get("success"):
                load_scores.append(1.0)

            load_score = (sum(load_scores) / len(load_scores)) * 25 if load_scores else 0
            score_components.append(("Tests de charge", load_score, 25))

        # Score de performance (25%)
        perf_score = 25  # Score par d√©faut si pas de goulots d'√©tranglement critiques
        if self.test_results.get("module_analysis", {}).get("bottlenecks"):
            bottleneck_count = len(self.test_results["module_analysis"]["bottlenecks"])
            perf_score = max(0, 25 - (bottleneck_count * 5))
        score_components.append(("Performance", perf_score, 25))

        # Affichage des composants du score
        total_score = 0
        for component, score, max_score in score_components:
            score_color = (
                Colors.GREEN if score >= max_score * 0.8 else Colors.YELLOW if score >= max_score * 0.6 else Colors.RED
            )
            report.append(f"{component}: {score_color}{score:.1f}/{max_score}{Colors.END}")
            total_score += score

        # Score final
        final_score_color = Colors.GREEN if total_score >= 80 else Colors.YELLOW if total_score >= 60 else Colors.RED

        # Sauvegarder le score calcul√© dans les r√©sultats
        self.test_results["calculated_score"] = total_score
        self.test_results["score_components"] = [
            {"component": comp, "score": sc, "max_score": max_sc} for comp, sc, max_sc in score_components
        ]

        report.append(f"\n{Colors.BOLD}SCORE GLOBAL: {final_score_color}{total_score:.1f}/100{Colors.END}")

        # √âvaluation qualitative
        if total_score >= 90:
            report.append(f"{Colors.GREEN}üåü EXCELLENCE - AGI Orchestrator exceptionnellement performant{Colors.END}")
        elif total_score >= 80:
            report.append(f"{Colors.GREEN}‚ú® TR√àS BIEN - AGI Orchestrator hautement fonctionnel{Colors.END}")
        elif total_score >= 70:
            report.append(f"{Colors.YELLOW}üëç BIEN - AGI Orchestrator satisfaisant{Colors.END}")
        elif total_score >= 60:
            report.append(f"{Colors.YELLOW}‚ö†Ô∏è MOYEN - AGI Orchestrator √† optimiser{Colors.END}")
        else:
            report.append(f"{Colors.RED}üîß FAIBLE - AGI Orchestrator n√©cessite des am√©liorations{Colors.END}")

        # 6. Recommandations
        report.append(f"\n{Colors.BOLD}{Colors.WHITE}üí° RECOMMANDATIONS{Colors.END}")
        report.append(f"{Colors.WHITE}{'-' * 40}{Colors.END}")

        # Recommandations bas√©es sur les r√©sultats
        if self.test_results.get("module_loading", {}).get("metrics", {}).get("success_rate", 1) < 0.8:
            report.append(f"{Colors.YELLOW}‚Ä¢ R√©parer les modules cerveau d√©faillants{Colors.END}")

        if self.test_results.get("module_analysis", {}).get("bottlenecks"):
            report.append(f"{Colors.YELLOW}‚Ä¢ Optimiser les modules identifi√©s comme goulots d'√©tranglement{Colors.END}")

        failed_comms = 0
        if self.test_results.get("inter_module_communication"):
            failed_comms = sum(1 for test in self.test_results["inter_module_communication"] if not test["success"])

        if failed_comms > 0:
            report.append(
                f"{Colors.YELLOW}‚Ä¢ Am√©liorer la communication inter-modules ({failed_comms} tests √©chou√©s){Colors.END}"
            )

        if self.test_results.get("load_testing", {}).get("10_requests", {}).get("success_rate", 1) < 0.9:
            report.append(f"{Colors.YELLOW}‚Ä¢ Am√©liorer la gestion des requ√™tes simultan√©es{Colors.END}")

        if self.test_results["errors"]:
            report.append(f"\n{Colors.RED}üö® Erreurs d√©tect√©es:{Colors.END}")
            for error in self.test_results["errors"]:
                report.append(f"{Colors.RED}‚Ä¢ {error}{Colors.END}")

        # Informations sur le diagramme
        flow_diagram_path = self.create_flow_diagram(self.test_results.get("module_analysis", {}))
        if flow_diagram_path:
            report.append(f"\n{Colors.GREEN}üìä Diagramme de flux sauvegard√©: {flow_diagram_path}{Colors.END}")

        report.append(f"\n{Colors.CYAN}{'=' * 80}{Colors.END}")

        return "\n".join(report)

    def run_all_tests(self):
        """Execute tous les tests de l'AGI Orchestrator"""
        print(f"{Colors.CYAN}üß† D√©marrage des tests AGI Orchestrator...{Colors.END}")

        # 1. Test de chargement des modules cerveau
        print(f"{Colors.BLUE}üì¶ Test chargement modules cerveau...{Colors.END}")
        success, message, metrics = self.test_brain_modules_loading()
        self.test_results["module_loading"] = {
            "success": success,
            "message": message,
            "metrics": metrics,
        }

        # 2. Test de communication inter-modules
        print(f"{Colors.GREEN}üîÑ Test communication inter-modules...{Colors.END}")
        communication_results = self.test_inter_module_communication()
        self.test_results["inter_module_communication"] = communication_results

        # 3. Tests de charge
        print(f"{Colors.YELLOW}‚ö° Tests de charge...{Colors.END}")
        load_results = self.test_load_performance()
        self.test_results["load_testing"] = load_results

        # 4. Analyse des modules
        print(f"{Colors.PURPLE}üìä Analyse utilisation modules...{Colors.END}")
        module_analysis = self.analyze_module_usage()
        self.test_results["module_analysis"] = module_analysis

        # 5. G√©n√©rer et afficher le rapport
        print(f"{Colors.CYAN}üìã G√©n√©ration du rapport...{Colors.END}")
        report = self.generate_report()

        # Afficher le rapport
        print(report)

        # Sauvegarder
        self.save_report(report)

        print(f"\n{Colors.GREEN}‚úÖ Rapport sauvegard√© dans test_results/agi_orchestrator_test.txt{Colors.END}")

    def save_report(self, colored_report: str):
        """Sauvegarde le rapport"""
        # Version sans couleurs pour le fichier
        import re

        clean_report = re.sub(r"\033\[[0-9;]*m", "", colored_report)

        # Sauvegarder le rapport texte
        report_file = self.project_root / "test_results" / "agi_orchestrator_test.txt"
        report_file.write_text(clean_report, encoding="utf-8")

        # Sauvegarder les donn√©es JSON
        json_file = self.project_root / "test_results" / "agi_orchestrator_test.json"
        with open(json_file, "w", encoding="utf-8") as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False)


def main():
    """Point d'entr√©e principal"""
    try:
        tester = AGIOrchestratorTester()
        tester.run_all_tests()
        return 0
    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}‚ö†Ô∏è Test interrompu par l'utilisateur{Colors.END}")
        return 1
    except Exception as e:
        print(f"\n{Colors.RED}‚ùå Erreur critique: {e}{Colors.END}")
        print(f"{Colors.RED}Traceback: {traceback.format_exc()}{Colors.END}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
