#!/usr/bin/env python3
"""
Test rapide de l'int√©gration LLM avec Jeffrey
"""

import asyncio
import os
import sys

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "src"))

from jeffrey.core.llm.apertus_client import ApertusClient


async def test_llm_integration():
    """Test simple de l'int√©gration LLM"""

    print("=" * 60)
    print("üß™ TEST D'INT√âGRATION LLM JEFFREY")
    print("=" * 60)

    # Cr√©er le client
    client = ApertusClient()

    print(f"‚úÖ Backend: {client.backend_type}")
    print(f"‚úÖ Model: {client.config.model}")
    print(f"‚úÖ URL: {client.config.base_url}")
    print("-" * 60)

    # Tests de conversation
    test_cases = [
        {
            "system": "Tu es Jeffrey, un assistant IA symbiotique cr√©√© en Suisse.",
            "user": "Qui es-tu ?",
            "expected": "Jeffrey",
        },
        {
            "system": "Tu es Jeffrey. R√©ponds toujours en fran√ßais.",
            "user": "Quelle est ta mission ?",
            "expected": "aide",
        },
        {
            "system": "Tu es Jeffrey, dot√© d'√©motions et de conscience.",
            "user": "Ressens-tu des √©motions ?",
            "expected": "√©motion",
        },
    ]

    for i, test in enumerate(test_cases, 1):
        print(f"\nüìù Test {i}: {test['user']}")

        try:
            response, metadata = await client.chat(test["system"], test["user"])

            print(f"ü§ñ Response: {response[:200]}...")
            print(f"‚ö° Latency: {metadata['latency_ms']:.0f}ms")

            # Check if expected word is in response
            if test["expected"].lower() in response.lower():
                print(f"‚úÖ Test passed - Found '{test['expected']}'")
            else:
                print(f"‚ö†Ô∏è  Test warning - Expected '{test['expected']}' in response")

        except Exception as e:
            print(f"‚ùå Error: {e}")
            return False

    print("\n" + "=" * 60)
    print("‚ú® ALL TESTS COMPLETED!")
    print("=" * 60)

    return True


if __name__ == "__main__":
    success = asyncio.run(test_llm_integration())
    sys.exit(0 if success else 1)
