#!/usr/bin/env python3
"""
Smoke test pour l'architecture CERVEAU Jeffrey
"""

import asyncio

from jeffrey.core.llm.autonomous_language_system import AutonomousLanguageSystem


async def smoke_test():
    """Test de fum√©e pour valider l'architecture"""
    print("üß™ Starting Jeffrey Brain Smoke Test\n")

    try:
        # 1. Initialiser le syst√®me
        print("1Ô∏è‚É£ Initializing Autonomous Language System...")
        als = AutonomousLanguageSystem(fallback_llm=None)
        await als.initialize()
        print("‚úÖ System initialized\n")

        # 2. Test simple sans LLM externe
        print("2Ô∏è‚É£ Testing autonomous generation...")
        query = {
            "content": "What is emergence?",
            "type": "question",
            "emotional_state": {"curiosity": 0.9},
        }

        result = await als.process(query, force_external=False)

        print(f"‚úÖ Success: {result['success']}")
        print(f"üìä Routing: {result['routing']}")
        print(f"üéØ Model: {result.get('model', 'unknown')}")
        print(f"‚≠ê Quality score: {result.get('quality_score', 0):.2f}")
        print(f"üí¨ Response: {result.get('response', 'No response')[:200]}...")
        print()

        # 3. Test avec diff√©rents contextes
        print("3Ô∏è‚É£ Testing different contexts...")
        test_queries = [
            {"content": "Tell me about consciousness", "type": "exploration"},
            {"content": "How do patterns emerge from chaos?", "type": "question"},
            {"content": "I wonder about the nature of awareness", "type": "reflection"},
        ]

        for i, test_query in enumerate(test_queries, 1):
            print(f"\nTest {i}: {test_query['content'][:50]}...")
            test_query["emotional_state"] = {"curiosity": 0.7, "wonder": 0.5}

            result = await als.process(test_query)
            print(f"  ‚Üí Routing: {result['routing']}")
            print(f"  ‚Üí Quality: {result.get('quality_score', 0):.2f}")

        # 4. V√©rifier les statistiques
        print("\n4Ô∏è‚É£ System Statistics:")
        stats = await als.get_stats()

        print(f"  ‚Üí Autonomy level: {stats['autonomy_level']:.3f}")
        print(f"  ‚Üí Cache size: {stats['cache_size']}")

        if "executive_stats" in stats:
            exec_stats = stats["executive_stats"]
            print(f"  ‚Üí Total decisions: {exec_stats['total_decisions']}")
            print(f"  ‚Üí Mean reward: {exec_stats['mean_reward']:.3f}")

        if "memory_stats" in stats:
            mem_stats = stats["memory_stats"]
            print(f"  ‚Üí Episodes stored: {mem_stats['episodic_memory_size']}")
            print(f"  ‚Üí Patterns: {mem_stats['semantic_patterns']}")

        # 5. V√©rifier la cr√©ation des fichiers
        print("\n5Ô∏è‚É£ Checking persistence...")
        from pathlib import Path

        files_to_check = ["data/episodic.db", "data/faiss.index", "data/lsh.pkl"]

        for file_path in files_to_check:
            exists = Path(file_path).exists()
            status = "‚úÖ" if exists else "‚ùå"
            print(f"  {status} {file_path}")

        # Cleanup
        await als.shutdown()
        print("\n‚úÖ Smoke test completed successfully!")

    except Exception as e:
        print(f"\n‚ùå Smoke test failed: {e}")
        import traceback

        traceback.print_exc()
        return False

    return True


if __name__ == "__main__":
    success = asyncio.run(smoke_test())
    exit(0 if success else 1)
